Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484D2X6CM7Ean3d.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.269621
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation rmse = 0.180477
Epoch 2
Validation rmse = 0.175057
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation rmse = 0.155382
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation rmse = 0.152049
Epoch 5
Validation rmse = 0.127462
Epoch 6
Loss = 9.1617e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation rmse = 0.124463
Epoch 7
Validation rmse = 0.109621
Epoch 8
Loss = 2.7033e-02, PNorm = 34.1663, GNorm = 1.5388, lr_0 = 5.3234e-04
Validation rmse = 0.100677
Epoch 9
Loss = 6.0310e-02, PNorm = 34.1833, GNorm = 1.1763, lr_0 = 4.6416e-04
Validation rmse = 0.096233
Epoch 10
Validation rmse = 0.088408
Epoch 11
Loss = 4.8576e-02, PNorm = 34.1980, GNorm = 3.0190, lr_0 = 3.9377e-04
Validation rmse = 0.088261
Epoch 12
Loss = 4.0376e-02, PNorm = 34.2081, GNorm = 2.1901, lr_0 = 3.3866e-04
Validation rmse = 0.072880
Epoch 13
Validation rmse = 0.074117
Epoch 14
Loss = 2.9638e-02, PNorm = 34.2176, GNorm = 1.5122, lr_0 = 2.9126e-04
Validation rmse = 0.075204
Epoch 15
Validation rmse = 0.067249
Epoch 16
Loss = 2.7263e-02, PNorm = 34.2254, GNorm = 0.4222, lr_0 = 2.4709e-04
Validation rmse = 0.064966
Epoch 17
Loss = 1.3779e-02, PNorm = 34.2301, GNorm = 0.8317, lr_0 = 2.1544e-04
Validation rmse = 0.063238
Epoch 18
Validation rmse = 0.062209
Epoch 19
Loss = 2.2177e-02, PNorm = 34.2347, GNorm = 1.1778, lr_0 = 1.8277e-04
Validation rmse = 0.061001
Epoch 20
Loss = 2.1519e-02, PNorm = 34.2381, GNorm = 1.5615, lr_0 = 1.5719e-04
Validation rmse = 0.060365
Epoch 21
Validation rmse = 0.063118
Epoch 22
Loss = 1.7815e-02, PNorm = 34.2411, GNorm = 0.7914, lr_0 = 1.3519e-04
Validation rmse = 0.058431
Epoch 23
Validation rmse = 0.059245
Epoch 24
Loss = 1.4564e-02, PNorm = 34.2439, GNorm = 0.4033, lr_0 = 1.1469e-04
Validation rmse = 0.057316
Epoch 25
Loss = 1.8541e-02, PNorm = 34.2460, GNorm = 1.4425, lr_0 = 1.0000e-04
Validation rmse = 0.057688
Epoch 26
Validation rmse = 0.059294
Epoch 27
Loss = 1.4505e-02, PNorm = 34.2485, GNorm = 0.2266, lr_0 = 1.0000e-04
Validation rmse = 0.057366
Epoch 28
Loss = 1.6110e-02, PNorm = 34.2508, GNorm = 0.6797, lr_0 = 1.0000e-04
Loss = 1.1988e-02, PNorm = 34.2509, GNorm = 0.6031, lr_0 = 1.0000e-04
Validation rmse = 0.055100
Epoch 29
Validation rmse = 0.056154
Model 0 best validation rmse = 0.055100 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.100295
Ensemble test rmse = 0.100295
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.165141
Epoch 1
Loss = 4.1795e-01, PNorm = 34.0376, GNorm = 1.5927, lr_0 = 1.0000e-03
Validation rmse = 0.141351
Epoch 2
Validation rmse = 0.129071
Epoch 3
Loss = 1.5872e-01, PNorm = 34.0896, GNorm = 2.2771, lr_0 = 8.4834e-04
Validation rmse = 0.155226
Epoch 4
Loss = 1.4736e-01, PNorm = 34.1228, GNorm = 0.7535, lr_0 = 7.2962e-04
Validation rmse = 0.129522
Epoch 5
Validation rmse = 0.105419
Epoch 6
Loss = 9.2302e-02, PNorm = 34.1491, GNorm = 1.6146, lr_0 = 6.2751e-04
Validation rmse = 0.098700
Epoch 7
Validation rmse = 0.108479
Epoch 8
Loss = 6.9239e-02, PNorm = 34.1743, GNorm = 3.3022, lr_0 = 5.3234e-04
Validation rmse = 0.086171
Epoch 9
Loss = 4.1668e-02, PNorm = 34.1901, GNorm = 0.3463, lr_0 = 4.6416e-04
Validation rmse = 0.084850
Epoch 10
Validation rmse = 0.080244
Epoch 11
Loss = 4.0361e-02, PNorm = 34.2036, GNorm = 1.5672, lr_0 = 3.9377e-04
Validation rmse = 0.075061
Epoch 12
Loss = 3.1749e-02, PNorm = 34.2126, GNorm = 3.1962, lr_0 = 3.3866e-04
Validation rmse = 0.074857
Epoch 13
Validation rmse = 0.072599
Epoch 14
Loss = 2.0363e-02, PNorm = 34.2190, GNorm = 0.2436, lr_0 = 2.9126e-04
Validation rmse = 0.066238
Epoch 15
Validation rmse = 0.063873
Epoch 16
Loss = 2.2169e-02, PNorm = 34.2257, GNorm = 0.7254, lr_0 = 2.4709e-04
Validation rmse = 0.063592
Epoch 17
Loss = 1.8420e-02, PNorm = 34.2305, GNorm = 1.2849, lr_0 = 2.1544e-04
Validation rmse = 0.072412
Epoch 18
Validation rmse = 0.062860
Epoch 19
Loss = 1.5132e-02, PNorm = 34.2339, GNorm = 1.2577, lr_0 = 1.8277e-04
Validation rmse = 0.068704
Epoch 20
Loss = 1.7073e-02, PNorm = 34.2364, GNorm = 0.8561, lr_0 = 1.5719e-04
Validation rmse = 0.062590
Epoch 21
Validation rmse = 0.064174
Epoch 22
Loss = 1.6229e-02, PNorm = 34.2398, GNorm = 1.5302, lr_0 = 1.3519e-04
Validation rmse = 0.058672
Epoch 23
Validation rmse = 0.058450
Epoch 24
Loss = 1.3637e-02, PNorm = 34.2419, GNorm = 0.6766, lr_0 = 1.1469e-04
Validation rmse = 0.058289
Epoch 25
Loss = 1.0752e-02, PNorm = 34.2435, GNorm = 0.6842, lr_0 = 1.0000e-04
Validation rmse = 0.056828
Epoch 26
Validation rmse = 0.056625
Epoch 27
Loss = 1.1614e-02, PNorm = 34.2455, GNorm = 0.7464, lr_0 = 1.0000e-04
Validation rmse = 0.055838
Epoch 28
Loss = 1.3119e-02, PNorm = 34.2474, GNorm = 0.6189, lr_0 = 1.0000e-04
Loss = 9.1975e-03, PNorm = 34.2476, GNorm = 0.7917, lr_0 = 1.0000e-04
Validation rmse = 0.059112
Epoch 29
Validation rmse = 0.056155
Model 0 best validation rmse = 0.055838 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.050819
Ensemble test rmse = 0.050819
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.198698
Epoch 1
Loss = 3.7305e-01, PNorm = 34.0380, GNorm = 4.0471, lr_0 = 1.0000e-03
Validation rmse = 0.165529
Epoch 2
Validation rmse = 0.171133
Epoch 3
Loss = 1.4358e-01, PNorm = 34.0912, GNorm = 1.3859, lr_0 = 8.4834e-04
Validation rmse = 0.131954
Epoch 4
Loss = 1.4428e-01, PNorm = 34.1190, GNorm = 1.3901, lr_0 = 7.2962e-04
Validation rmse = 0.117991
Epoch 5
Validation rmse = 0.102099
Epoch 6
Loss = 8.0058e-02, PNorm = 34.1417, GNorm = 1.5776, lr_0 = 6.2751e-04
Validation rmse = 0.093086
Epoch 7
Validation rmse = 0.090354
Epoch 8
Loss = 6.8895e-02, PNorm = 34.1629, GNorm = 3.0916, lr_0 = 5.3234e-04
Validation rmse = 0.081313
Epoch 9
Loss = 5.4840e-02, PNorm = 34.1760, GNorm = 3.1879, lr_0 = 4.6416e-04
Validation rmse = 0.083599
Epoch 10
Validation rmse = 0.069874
Epoch 11
Loss = 4.5203e-02, PNorm = 34.1893, GNorm = 2.5113, lr_0 = 3.9377e-04
Validation rmse = 0.070037
Epoch 12
Loss = 3.3131e-02, PNorm = 34.1986, GNorm = 1.0398, lr_0 = 3.3866e-04
Validation rmse = 0.065953
Epoch 13
Validation rmse = 0.068254
Epoch 14
Loss = 2.3628e-02, PNorm = 34.2055, GNorm = 0.5169, lr_0 = 2.9126e-04
Validation rmse = 0.062620
Epoch 15
Validation rmse = 0.058199
Epoch 16
Loss = 1.6729e-02, PNorm = 34.2116, GNorm = 1.2696, lr_0 = 2.4709e-04
Validation rmse = 0.057762
Epoch 17
Loss = 2.2852e-02, PNorm = 34.2156, GNorm = 0.3260, lr_0 = 2.1544e-04
Validation rmse = 0.055195
Epoch 18
Validation rmse = 0.054008
Epoch 19
Loss = 2.0986e-02, PNorm = 34.2200, GNorm = 0.6456, lr_0 = 1.8277e-04
Validation rmse = 0.053400
Epoch 20
Loss = 1.9108e-02, PNorm = 34.2232, GNorm = 0.7060, lr_0 = 1.5719e-04
Validation rmse = 0.052595
Epoch 21
Validation rmse = 0.055991
Epoch 22
Loss = 2.0893e-02, PNorm = 34.2259, GNorm = 1.1869, lr_0 = 1.3519e-04
Validation rmse = 0.052067
Epoch 23
Validation rmse = 0.056931
Epoch 24
Loss = 2.1023e-02, PNorm = 34.2286, GNorm = 1.8903, lr_0 = 1.1469e-04
Validation rmse = 0.058807
Epoch 25
Loss = 2.0197e-02, PNorm = 34.2306, GNorm = 0.7277, lr_0 = 1.0000e-04
Validation rmse = 0.047107
Epoch 26
Validation rmse = 0.046317
Epoch 27
Loss = 2.3994e-02, PNorm = 34.2328, GNorm = 0.6443, lr_0 = 1.0000e-04
Validation rmse = 0.045558
Epoch 28
Loss = 1.4498e-02, PNorm = 34.2348, GNorm = 0.3728, lr_0 = 1.0000e-04
Loss = 4.4235e-02, PNorm = 34.2350, GNorm = 1.6257, lr_0 = 1.0000e-04
Validation rmse = 0.045674
Epoch 29
Validation rmse = 0.047655
Model 0 best validation rmse = 0.045558 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.055902
Ensemble test rmse = 0.055902
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.270396
Epoch 1
Loss = 3.6348e-01, PNorm = 34.0356, GNorm = 4.0663, lr_0 = 1.0000e-03
Validation rmse = 0.231706
Epoch 2
Validation rmse = 0.187757
Epoch 3
Loss = 2.0102e-01, PNorm = 34.0805, GNorm = 1.1718, lr_0 = 8.4834e-04
Validation rmse = 0.166576
Epoch 4
Loss = 1.5701e-01, PNorm = 34.1086, GNorm = 1.0196, lr_0 = 7.2962e-04
Validation rmse = 0.159889
Epoch 5
Validation rmse = 0.139427
Epoch 6
Loss = 1.1482e-01, PNorm = 34.1371, GNorm = 3.9211, lr_0 = 6.2751e-04
Validation rmse = 0.111297
Epoch 7
Validation rmse = 0.105106
Epoch 8
Loss = 1.2792e-01, PNorm = 34.1575, GNorm = 1.0524, lr_0 = 5.3234e-04
Validation rmse = 0.100201
Epoch 9
Loss = 7.4187e-02, PNorm = 34.1739, GNorm = 0.4970, lr_0 = 4.6416e-04
Validation rmse = 0.080587
Epoch 10
Validation rmse = 0.082505
Epoch 11
Loss = 4.2506e-02, PNorm = 34.1898, GNorm = 0.6771, lr_0 = 3.9377e-04
Validation rmse = 0.078113
Epoch 12
Loss = 4.2591e-02, PNorm = 34.2010, GNorm = 2.1086, lr_0 = 3.3866e-04
Validation rmse = 0.080181
Epoch 13
Validation rmse = 0.069468
Epoch 14
Loss = 4.0271e-02, PNorm = 34.2095, GNorm = 3.0138, lr_0 = 2.9126e-04
Validation rmse = 0.088481
Epoch 15
Validation rmse = 0.069020
Epoch 16
Loss = 3.1943e-02, PNorm = 34.2155, GNorm = 0.9060, lr_0 = 2.4709e-04
Validation rmse = 0.069010
Epoch 17
Loss = 2.3741e-02, PNorm = 34.2209, GNorm = 0.4997, lr_0 = 2.1544e-04
Validation rmse = 0.065229
Epoch 18
Validation rmse = 0.063212
Epoch 19
Loss = 1.7346e-02, PNorm = 34.2265, GNorm = 0.6876, lr_0 = 1.8277e-04
Validation rmse = 0.060127
Epoch 20
Loss = 2.2248e-02, PNorm = 34.2306, GNorm = 0.5047, lr_0 = 1.5719e-04
Validation rmse = 0.061558
Epoch 21
Validation rmse = 0.061234
Epoch 22
Loss = 1.6916e-02, PNorm = 34.2333, GNorm = 0.8523, lr_0 = 1.3519e-04
Validation rmse = 0.060315
Epoch 23
Validation rmse = 0.058760
Epoch 24
Loss = 1.6713e-02, PNorm = 34.2360, GNorm = 1.3916, lr_0 = 1.1469e-04
Validation rmse = 0.059403
Epoch 25
Loss = 1.5279e-02, PNorm = 34.2382, GNorm = 1.1411, lr_0 = 1.0000e-04
Validation rmse = 0.056963
Epoch 26
Validation rmse = 0.060237
Epoch 27
Loss = 1.8870e-02, PNorm = 34.2401, GNorm = 0.6127, lr_0 = 1.0000e-04
Validation rmse = 0.056353
Epoch 28
Loss = 1.7129e-02, PNorm = 34.2416, GNorm = 0.3120, lr_0 = 1.0000e-04
Loss = 2.4059e-02, PNorm = 34.2418, GNorm = 1.7847, lr_0 = 1.0000e-04
Validation rmse = 0.059296
Epoch 29
Validation rmse = 0.056115
Model 0 best validation rmse = 0.056115 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.056671
Ensemble test rmse = 0.056671
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.233935
Epoch 1
Loss = 4.6429e-01, PNorm = 34.0363, GNorm = 4.3415, lr_0 = 1.0000e-03
Validation rmse = 0.168265
Epoch 2
Validation rmse = 0.141788
Epoch 3
Loss = 1.7557e-01, PNorm = 34.0811, GNorm = 1.0197, lr_0 = 8.4834e-04
Validation rmse = 0.127522
Epoch 4
Loss = 1.5640e-01, PNorm = 34.1123, GNorm = 2.7805, lr_0 = 7.2962e-04
Validation rmse = 0.123559
Epoch 5
Validation rmse = 0.104121
Epoch 6
Loss = 1.1123e-01, PNorm = 34.1401, GNorm = 0.5744, lr_0 = 6.2751e-04
Validation rmse = 0.097648
Epoch 7
Validation rmse = 0.088834
Epoch 8
Loss = 7.7614e-02, PNorm = 34.1661, GNorm = 0.6865, lr_0 = 5.3234e-04
Validation rmse = 0.082419
Epoch 9
Loss = 5.4041e-02, PNorm = 34.1838, GNorm = 1.3418, lr_0 = 4.6416e-04
Validation rmse = 0.086506
Epoch 10
Validation rmse = 0.073704
Epoch 11
Loss = 4.7097e-02, PNorm = 34.1957, GNorm = 4.5539, lr_0 = 3.9377e-04
Validation rmse = 0.090654
Epoch 12
Loss = 5.6615e-02, PNorm = 34.2048, GNorm = 3.8230, lr_0 = 3.3866e-04
Validation rmse = 0.062653
Epoch 13
Validation rmse = 0.067393
Epoch 14
Loss = 3.6112e-02, PNorm = 34.2124, GNorm = 1.6932, lr_0 = 2.9126e-04
Validation rmse = 0.066322
Epoch 15
Validation rmse = 0.064946
Epoch 16
Loss = 3.3403e-02, PNorm = 34.2199, GNorm = 1.1806, lr_0 = 2.4709e-04
Validation rmse = 0.061870
Epoch 17
Loss = 2.4763e-02, PNorm = 34.2249, GNorm = 0.7020, lr_0 = 2.1544e-04
Validation rmse = 0.062841
Epoch 18
Validation rmse = 0.062351
Epoch 19
Loss = 2.0723e-02, PNorm = 34.2294, GNorm = 0.6583, lr_0 = 1.8277e-04
Validation rmse = 0.062351
Epoch 20
Loss = 1.8998e-02, PNorm = 34.2329, GNorm = 0.3751, lr_0 = 1.5719e-04
Validation rmse = 0.059542
Epoch 21
Validation rmse = 0.059659
Epoch 22
Loss = 1.7906e-02, PNorm = 34.2358, GNorm = 0.1906, lr_0 = 1.3519e-04
Validation rmse = 0.060171
Epoch 23
Validation rmse = 0.059128
Epoch 24
Loss = 2.5433e-02, PNorm = 34.2387, GNorm = 0.2526, lr_0 = 1.1469e-04
Validation rmse = 0.060341
Epoch 25
Loss = 1.7791e-02, PNorm = 34.2406, GNorm = 0.6430, lr_0 = 1.0000e-04
Validation rmse = 0.060127
Epoch 26
Validation rmse = 0.058273
Epoch 27
Loss = 1.5250e-02, PNorm = 34.2429, GNorm = 0.9804, lr_0 = 1.0000e-04
Validation rmse = 0.058335
Epoch 28
Loss = 1.6483e-02, PNorm = 34.2458, GNorm = 0.5621, lr_0 = 1.0000e-04
Loss = 7.1196e-03, PNorm = 34.2460, GNorm = 1.3939, lr_0 = 1.0000e-04
Validation rmse = 0.059827
Epoch 29
Validation rmse = 0.059045
Model 0 best validation rmse = 0.058273 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.067995
Ensemble test rmse = 0.067995
5-fold cross validation
	Seed 0 ==> test rmse = 0.100295
	Seed 1 ==> test rmse = 0.050819
	Seed 2 ==> test rmse = 0.055902
	Seed 3 ==> test rmse = 0.056671
	Seed 4 ==> test rmse = 0.067995
Overall test rmse = 0.066336 +/- 0.017883
Elapsed time = 0:02:06
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484D2X6CM7Ean3d.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.269621
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation rmse = 0.180477
Epoch 2
Validation rmse = 0.175057
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation rmse = 0.155382
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation rmse = 0.152049
Epoch 5
Validation rmse = 0.127462
Epoch 6
Loss = 9.1617e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation rmse = 0.124463
Epoch 7
Validation rmse = 0.109621
Epoch 8
Loss = 2.7033e-02, PNorm = 34.1663, GNorm = 1.5388, lr_0 = 5.3234e-04
Validation rmse = 0.100677
Epoch 9
Loss = 6.0310e-02, PNorm = 34.1833, GNorm = 1.1763, lr_0 = 4.6416e-04
Validation rmse = 0.096233
Epoch 10
Validation rmse = 0.088408
Epoch 11
Loss = 4.8576e-02, PNorm = 34.1980, GNorm = 3.0190, lr_0 = 3.9377e-04
Validation rmse = 0.088261
Epoch 12
Loss = 4.0376e-02, PNorm = 34.2081, GNorm = 2.1901, lr_0 = 3.3866e-04
Validation rmse = 0.072880
Epoch 13
Validation rmse = 0.074117
Epoch 14
Loss = 2.9638e-02, PNorm = 34.2176, GNorm = 1.5122, lr_0 = 2.9126e-04
Validation rmse = 0.075204
Epoch 15
Validation rmse = 0.067249
Epoch 16
Loss = 2.7263e-02, PNorm = 34.2254, GNorm = 0.4222, lr_0 = 2.4709e-04
Validation rmse = 0.064966
Epoch 17
Loss = 1.3779e-02, PNorm = 34.2301, GNorm = 0.8317, lr_0 = 2.1544e-04
Validation rmse = 0.063238
Epoch 18
Validation rmse = 0.062209
Epoch 19
Loss = 2.2177e-02, PNorm = 34.2347, GNorm = 1.1778, lr_0 = 1.8277e-04
Validation rmse = 0.061001
Epoch 20
Loss = 2.1519e-02, PNorm = 34.2381, GNorm = 1.5615, lr_0 = 1.5719e-04
Validation rmse = 0.060365
Epoch 21
Validation rmse = 0.063118
Epoch 22
Loss = 1.7815e-02, PNorm = 34.2411, GNorm = 0.7914, lr_0 = 1.3519e-04
Validation rmse = 0.058431
Epoch 23
Validation rmse = 0.059245
Epoch 24
Loss = 1.4564e-02, PNorm = 34.2439, GNorm = 0.4033, lr_0 = 1.1469e-04
Validation rmse = 0.057316
Epoch 25
Loss = 1.8541e-02, PNorm = 34.2460, GNorm = 1.4425, lr_0 = 1.0000e-04
Validation rmse = 0.057688
Epoch 26
Validation rmse = 0.059294
Epoch 27
Loss = 1.4505e-02, PNorm = 34.2485, GNorm = 0.2266, lr_0 = 1.0000e-04
Validation rmse = 0.057366
Epoch 28
Loss = 1.6110e-02, PNorm = 34.2508, GNorm = 0.6797, lr_0 = 1.0000e-04
Loss = 1.1988e-02, PNorm = 34.2509, GNorm = 0.6031, lr_0 = 1.0000e-04
Validation rmse = 0.055100
Epoch 29
Validation rmse = 0.056154
Model 0 best validation rmse = 0.055100 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.100295
Ensemble test rmse = 0.100295
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.165141
Epoch 1
Loss = 4.1795e-01, PNorm = 34.0376, GNorm = 1.5927, lr_0 = 1.0000e-03
Validation rmse = 0.141351
Epoch 2
Validation rmse = 0.129071
Epoch 3
Loss = 1.5872e-01, PNorm = 34.0896, GNorm = 2.2771, lr_0 = 8.4834e-04
Validation rmse = 0.155226
Epoch 4
Loss = 1.4736e-01, PNorm = 34.1228, GNorm = 0.7535, lr_0 = 7.2962e-04
Validation rmse = 0.129522
Epoch 5
Validation rmse = 0.105419
Epoch 6
Loss = 9.2302e-02, PNorm = 34.1491, GNorm = 1.6146, lr_0 = 6.2751e-04
Validation rmse = 0.098700
Epoch 7
Validation rmse = 0.108479
Epoch 8
Loss = 6.9239e-02, PNorm = 34.1743, GNorm = 3.3022, lr_0 = 5.3234e-04
Validation rmse = 0.086171
Epoch 9
Loss = 4.1668e-02, PNorm = 34.1901, GNorm = 0.3463, lr_0 = 4.6416e-04
Validation rmse = 0.084850
Epoch 10
Validation rmse = 0.080244
Epoch 11
Loss = 4.0361e-02, PNorm = 34.2036, GNorm = 1.5672, lr_0 = 3.9377e-04
Validation rmse = 0.075061
Epoch 12
Loss = 3.1749e-02, PNorm = 34.2126, GNorm = 3.1962, lr_0 = 3.3866e-04
Validation rmse = 0.074857
Epoch 13
Validation rmse = 0.072599
Epoch 14
Loss = 2.0363e-02, PNorm = 34.2190, GNorm = 0.2436, lr_0 = 2.9126e-04
Validation rmse = 0.066238
Epoch 15
Validation rmse = 0.063873
Epoch 16
Loss = 2.2169e-02, PNorm = 34.2257, GNorm = 0.7254, lr_0 = 2.4709e-04
Validation rmse = 0.063592
Epoch 17
Loss = 1.8420e-02, PNorm = 34.2305, GNorm = 1.2849, lr_0 = 2.1544e-04
Validation rmse = 0.072412
Epoch 18
Validation rmse = 0.062860
Epoch 19
Loss = 1.5132e-02, PNorm = 34.2339, GNorm = 1.2577, lr_0 = 1.8277e-04
Validation rmse = 0.068704
Epoch 20
Loss = 1.7073e-02, PNorm = 34.2364, GNorm = 0.8561, lr_0 = 1.5719e-04
Validation rmse = 0.062590
Epoch 21
Validation rmse = 0.064174
Epoch 22
Loss = 1.6229e-02, PNorm = 34.2398, GNorm = 1.5302, lr_0 = 1.3519e-04
Validation rmse = 0.058672
Epoch 23
Validation rmse = 0.058450
Epoch 24
Loss = 1.3637e-02, PNorm = 34.2419, GNorm = 0.6766, lr_0 = 1.1469e-04
Validation rmse = 0.058289
Epoch 25
Loss = 1.0752e-02, PNorm = 34.2435, GNorm = 0.6842, lr_0 = 1.0000e-04
Validation rmse = 0.056828
Epoch 26
Validation rmse = 0.056625
Epoch 27
Loss = 1.1614e-02, PNorm = 34.2455, GNorm = 0.7464, lr_0 = 1.0000e-04
Validation rmse = 0.055838
Epoch 28
Loss = 1.3119e-02, PNorm = 34.2474, GNorm = 0.6189, lr_0 = 1.0000e-04
Loss = 9.1975e-03, PNorm = 34.2476, GNorm = 0.7917, lr_0 = 1.0000e-04
Validation rmse = 0.059112
Epoch 29
Validation rmse = 0.056155
Model 0 best validation rmse = 0.055838 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.050819
Ensemble test rmse = 0.050819
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.198698
Epoch 1
Loss = 3.7305e-01, PNorm = 34.0380, GNorm = 4.0471, lr_0 = 1.0000e-03
Validation rmse = 0.165529
Epoch 2
Validation rmse = 0.171133
Epoch 3
Loss = 1.4358e-01, PNorm = 34.0912, GNorm = 1.3859, lr_0 = 8.4834e-04
Validation rmse = 0.131954
Epoch 4
Loss = 1.4428e-01, PNorm = 34.1190, GNorm = 1.3901, lr_0 = 7.2962e-04
Validation rmse = 0.117991
Epoch 5
Validation rmse = 0.102099
Epoch 6
Loss = 8.0058e-02, PNorm = 34.1417, GNorm = 1.5776, lr_0 = 6.2751e-04
Validation rmse = 0.093086
Epoch 7
Validation rmse = 0.090354
Epoch 8
Loss = 6.8895e-02, PNorm = 34.1629, GNorm = 3.0916, lr_0 = 5.3234e-04
Validation rmse = 0.081313
Epoch 9
Loss = 5.4840e-02, PNorm = 34.1760, GNorm = 3.1879, lr_0 = 4.6416e-04
Validation rmse = 0.083599
Epoch 10
Validation rmse = 0.069874
Epoch 11
Loss = 4.5203e-02, PNorm = 34.1893, GNorm = 2.5113, lr_0 = 3.9377e-04
Validation rmse = 0.070037
Epoch 12
Loss = 3.3131e-02, PNorm = 34.1986, GNorm = 1.0398, lr_0 = 3.3866e-04
Validation rmse = 0.065953
Epoch 13
Validation rmse = 0.068254
Epoch 14
Loss = 2.3628e-02, PNorm = 34.2055, GNorm = 0.5169, lr_0 = 2.9126e-04
Validation rmse = 0.062620
Epoch 15
Validation rmse = 0.058199
Epoch 16
Loss = 1.6730e-02, PNorm = 34.2116, GNorm = 1.2697, lr_0 = 2.4709e-04
Validation rmse = 0.057762
Epoch 17
Loss = 2.2852e-02, PNorm = 34.2156, GNorm = 0.3264, lr_0 = 2.1544e-04
Validation rmse = 0.055196
Epoch 18
Validation rmse = 0.054008
Epoch 19
Loss = 2.0984e-02, PNorm = 34.2200, GNorm = 0.6457, lr_0 = 1.8277e-04
Validation rmse = 0.053397
Epoch 20
Loss = 1.9107e-02, PNorm = 34.2232, GNorm = 0.7040, lr_0 = 1.5719e-04
Validation rmse = 0.052591
Epoch 21
Validation rmse = 0.055992
Epoch 22
Loss = 2.0897e-02, PNorm = 34.2259, GNorm = 1.1929, lr_0 = 1.3519e-04
Validation rmse = 0.052081
Epoch 23
Validation rmse = 0.056937
Epoch 24
Loss = 2.1035e-02, PNorm = 34.2286, GNorm = 1.8911, lr_0 = 1.1469e-04
Validation rmse = 0.058813
Epoch 25
Loss = 2.0194e-02, PNorm = 34.2307, GNorm = 0.7298, lr_0 = 1.0000e-04
Validation rmse = 0.047104
Epoch 26
Validation rmse = 0.046309
Epoch 27
Loss = 2.3993e-02, PNorm = 34.2328, GNorm = 0.6460, lr_0 = 1.0000e-04
Validation rmse = 0.045555
Epoch 28
Loss = 1.4500e-02, PNorm = 34.2348, GNorm = 0.3728, lr_0 = 1.0000e-04
Loss = 4.4268e-02, PNorm = 34.2350, GNorm = 1.6291, lr_0 = 1.0000e-04
Validation rmse = 0.045681
Epoch 29
Validation rmse = 0.047638
Model 0 best validation rmse = 0.045555 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.055897
Ensemble test rmse = 0.055897
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.270396
Epoch 1
Loss = 3.6348e-01, PNorm = 34.0356, GNorm = 4.0663, lr_0 = 1.0000e-03
Validation rmse = 0.231706
Epoch 2
Validation rmse = 0.187757
Epoch 3
Loss = 2.0102e-01, PNorm = 34.0805, GNorm = 1.1718, lr_0 = 8.4834e-04
Validation rmse = 0.166576
Epoch 4
Loss = 1.5701e-01, PNorm = 34.1086, GNorm = 1.0196, lr_0 = 7.2962e-04
Validation rmse = 0.159889
Epoch 5
Validation rmse = 0.139427
Epoch 6
Loss = 1.1482e-01, PNorm = 34.1371, GNorm = 3.9211, lr_0 = 6.2751e-04
Validation rmse = 0.111297
Epoch 7
Validation rmse = 0.105106
Epoch 8
Loss = 1.2792e-01, PNorm = 34.1575, GNorm = 1.0524, lr_0 = 5.3234e-04
Validation rmse = 0.100201
Epoch 9
Loss = 7.4187e-02, PNorm = 34.1739, GNorm = 0.4970, lr_0 = 4.6416e-04
Validation rmse = 0.080587
Epoch 10
Validation rmse = 0.082505
Epoch 11
Loss = 4.2506e-02, PNorm = 34.1898, GNorm = 0.6771, lr_0 = 3.9377e-04
Validation rmse = 0.078113
Epoch 12
Loss = 4.2591e-02, PNorm = 34.2010, GNorm = 2.1086, lr_0 = 3.3866e-04
Validation rmse = 0.080181
Epoch 13
Validation rmse = 0.069468
Epoch 14
Loss = 4.0271e-02, PNorm = 34.2095, GNorm = 3.0138, lr_0 = 2.9126e-04
Validation rmse = 0.088481
Epoch 15
Validation rmse = 0.069020
Epoch 16
Loss = 3.1943e-02, PNorm = 34.2155, GNorm = 0.9060, lr_0 = 2.4709e-04
Validation rmse = 0.069010
Epoch 17
Loss = 2.3741e-02, PNorm = 34.2209, GNorm = 0.4997, lr_0 = 2.1544e-04
Validation rmse = 0.065229
Epoch 18
Validation rmse = 0.063212
Epoch 19
Loss = 1.7346e-02, PNorm = 34.2265, GNorm = 0.6876, lr_0 = 1.8277e-04
Validation rmse = 0.060127
Epoch 20
Loss = 2.2248e-02, PNorm = 34.2306, GNorm = 0.5047, lr_0 = 1.5719e-04
Validation rmse = 0.061558
Epoch 21
Validation rmse = 0.061234
Epoch 22
Loss = 1.6916e-02, PNorm = 34.2333, GNorm = 0.8523, lr_0 = 1.3519e-04
Validation rmse = 0.060315
Epoch 23
Validation rmse = 0.058760
Epoch 24
Loss = 1.6713e-02, PNorm = 34.2360, GNorm = 1.3916, lr_0 = 1.1469e-04
Validation rmse = 0.059403
Epoch 25
Loss = 1.5279e-02, PNorm = 34.2382, GNorm = 1.1411, lr_0 = 1.0000e-04
Validation rmse = 0.056963
Epoch 26
Validation rmse = 0.060237
Epoch 27
Loss = 1.8870e-02, PNorm = 34.2401, GNorm = 0.6127, lr_0 = 1.0000e-04
Validation rmse = 0.056353
Epoch 28
Loss = 1.7129e-02, PNorm = 34.2416, GNorm = 0.3120, lr_0 = 1.0000e-04
Loss = 2.4059e-02, PNorm = 34.2418, GNorm = 1.7847, lr_0 = 1.0000e-04
Validation rmse = 0.059296
Epoch 29
Validation rmse = 0.056115
Model 0 best validation rmse = 0.056115 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.056671
Ensemble test rmse = 0.056671
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.233935
Epoch 1
Loss = 4.6429e-01, PNorm = 34.0363, GNorm = 4.3415, lr_0 = 1.0000e-03
Validation rmse = 0.168265
Epoch 2
Validation rmse = 0.141788
Epoch 3
Loss = 1.7557e-01, PNorm = 34.0811, GNorm = 1.0197, lr_0 = 8.4834e-04
Validation rmse = 0.127522
Epoch 4
Loss = 1.5640e-01, PNorm = 34.1123, GNorm = 2.7805, lr_0 = 7.2962e-04
Validation rmse = 0.123559
Epoch 5
Validation rmse = 0.104121
Epoch 6
Loss = 1.1123e-01, PNorm = 34.1401, GNorm = 0.5744, lr_0 = 6.2751e-04
Validation rmse = 0.097648
Epoch 7
Validation rmse = 0.088834
Epoch 8
Loss = 7.7614e-02, PNorm = 34.1661, GNorm = 0.6865, lr_0 = 5.3234e-04
Validation rmse = 0.082419
Epoch 9
Loss = 5.4041e-02, PNorm = 34.1838, GNorm = 1.3418, lr_0 = 4.6416e-04
Validation rmse = 0.086506
Epoch 10
Validation rmse = 0.073704
Epoch 11
Loss = 4.7097e-02, PNorm = 34.1957, GNorm = 4.5539, lr_0 = 3.9377e-04
Validation rmse = 0.090654
Epoch 12
Loss = 5.6615e-02, PNorm = 34.2048, GNorm = 3.8230, lr_0 = 3.3866e-04
Validation rmse = 0.062653
Epoch 13
Validation rmse = 0.067393
Epoch 14
Loss = 3.6112e-02, PNorm = 34.2124, GNorm = 1.6932, lr_0 = 2.9126e-04
Validation rmse = 0.066322
Epoch 15
Validation rmse = 0.064946
Epoch 16
Loss = 3.3403e-02, PNorm = 34.2199, GNorm = 1.1806, lr_0 = 2.4709e-04
Validation rmse = 0.061870
Epoch 17
Loss = 2.4763e-02, PNorm = 34.2249, GNorm = 0.7020, lr_0 = 2.1544e-04
Validation rmse = 0.062841
Epoch 18
Validation rmse = 0.062351
Epoch 19
Loss = 2.0723e-02, PNorm = 34.2294, GNorm = 0.6583, lr_0 = 1.8277e-04
Validation rmse = 0.062351
Epoch 20
Loss = 1.8998e-02, PNorm = 34.2329, GNorm = 0.3751, lr_0 = 1.5719e-04
Validation rmse = 0.059542
Epoch 21
Validation rmse = 0.059659
Epoch 22
Loss = 1.7906e-02, PNorm = 34.2358, GNorm = 0.1906, lr_0 = 1.3519e-04
Validation rmse = 0.060171
Epoch 23
Validation rmse = 0.059128
Epoch 24
Loss = 2.5433e-02, PNorm = 34.2387, GNorm = 0.2526, lr_0 = 1.1469e-04
Validation rmse = 0.060341
Epoch 25
Loss = 1.7791e-02, PNorm = 34.2406, GNorm = 0.6430, lr_0 = 1.0000e-04
Validation rmse = 0.060127
Epoch 26
Validation rmse = 0.058273
Epoch 27
Loss = 1.5250e-02, PNorm = 34.2429, GNorm = 0.9804, lr_0 = 1.0000e-04
Validation rmse = 0.058335
Epoch 28
Loss = 1.6483e-02, PNorm = 34.2458, GNorm = 0.5621, lr_0 = 1.0000e-04
Loss = 7.1196e-03, PNorm = 34.2460, GNorm = 1.3939, lr_0 = 1.0000e-04
Validation rmse = 0.059827
Epoch 29
Validation rmse = 0.059045
Model 0 best validation rmse = 0.058273 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.067995
Ensemble test rmse = 0.067995
5-fold cross validation
	Seed 0 ==> test rmse = 0.100295
	Seed 1 ==> test rmse = 0.050819
	Seed 2 ==> test rmse = 0.055897
	Seed 3 ==> test rmse = 0.056671
	Seed 4 ==> test rmse = 0.067995
Overall test rmse = 0.066335 +/- 0.017884
Elapsed time = 0:02:06
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484D2X6CM7Ean3d.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.490594
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation r2 = 0.771756
Epoch 2
Validation r2 = 0.785258
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation r2 = 0.830818
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation r2 = 0.837998
Epoch 5
Validation r2 = 0.886153
Epoch 6
Loss = 9.1617e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation r2 = 0.891449
Epoch 7
Validation r2 = 0.915794
Epoch 8
Loss = 2.7033e-02, PNorm = 34.1663, GNorm = 1.5388, lr_0 = 5.3234e-04
Validation r2 = 0.928974
Epoch 9
Loss = 6.0310e-02, PNorm = 34.1833, GNorm = 1.1763, lr_0 = 4.6416e-04
Validation r2 = 0.935106
Epoch 10
Validation r2 = 0.945230
Epoch 11
Loss = 4.8576e-02, PNorm = 34.1980, GNorm = 3.0190, lr_0 = 3.9377e-04
Validation r2 = 0.945413
Epoch 12
Loss = 4.0376e-02, PNorm = 34.2081, GNorm = 2.1901, lr_0 = 3.3866e-04
Validation r2 = 0.962781
Epoch 13
Validation r2 = 0.961506
Epoch 14
Loss = 2.9638e-02, PNorm = 34.2176, GNorm = 1.5122, lr_0 = 2.9126e-04
Validation r2 = 0.960369
Epoch 15
Validation r2 = 0.968309
Epoch 16
Loss = 2.7263e-02, PNorm = 34.2254, GNorm = 0.4222, lr_0 = 2.4709e-04
Validation r2 = 0.970424
Epoch 17
Loss = 1.3779e-02, PNorm = 34.2301, GNorm = 0.8317, lr_0 = 2.1544e-04
Validation r2 = 0.971976
Epoch 18
Validation r2 = 0.972881
Epoch 19
Loss = 2.2179e-02, PNorm = 34.2347, GNorm = 1.1786, lr_0 = 1.8277e-04
Validation r2 = 0.973928
Epoch 20
Loss = 2.1522e-02, PNorm = 34.2381, GNorm = 1.5636, lr_0 = 1.5719e-04
Validation r2 = 0.974472
Epoch 21
Validation r2 = 0.972085
Epoch 22
Loss = 1.7815e-02, PNorm = 34.2411, GNorm = 0.7906, lr_0 = 1.3519e-04
Validation r2 = 0.976083
Epoch 23
Validation r2 = 0.975402
Epoch 24
Loss = 1.4561e-02, PNorm = 34.2439, GNorm = 0.4047, lr_0 = 1.1469e-04
Validation r2 = 0.976975
Epoch 25
Loss = 1.8541e-02, PNorm = 34.2460, GNorm = 1.4437, lr_0 = 1.0000e-04
Validation r2 = 0.976678
Epoch 26
Validation r2 = 0.975350
Epoch 27
Loss = 1.4509e-02, PNorm = 34.2485, GNorm = 0.2222, lr_0 = 1.0000e-04
Validation r2 = 0.976940
Epoch 28
Loss = 1.6111e-02, PNorm = 34.2508, GNorm = 0.6810, lr_0 = 1.0000e-04
Loss = 1.1992e-02, PNorm = 34.2510, GNorm = 0.6051, lr_0 = 1.0000e-04
Validation r2 = 0.978728
Epoch 29
Validation r2 = 0.977916
Model 0 best validation r2 = 0.978728 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.940272
Ensemble test r2 = 0.940272
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.608807
Epoch 1
Loss = 4.1795e-01, PNorm = 34.0376, GNorm = 1.5927, lr_0 = 1.0000e-03
Validation r2 = 0.713398
Epoch 2
Validation r2 = 0.761033
Epoch 3
Loss = 1.5872e-01, PNorm = 34.0896, GNorm = 2.2771, lr_0 = 8.4834e-04
Validation r2 = 0.654372
Epoch 4
Loss = 1.4736e-01, PNorm = 34.1228, GNorm = 0.7535, lr_0 = 7.2962e-04
Validation r2 = 0.759359
Epoch 5
Validation r2 = 0.840587
Epoch 6
Loss = 9.2302e-02, PNorm = 34.1491, GNorm = 1.6146, lr_0 = 6.2751e-04
Validation r2 = 0.860262
Epoch 7
Validation r2 = 0.831200
Epoch 8
Loss = 6.9239e-02, PNorm = 34.1743, GNorm = 3.3022, lr_0 = 5.3234e-04
Validation r2 = 0.893487
Epoch 9
Loss = 4.1668e-02, PNorm = 34.1901, GNorm = 0.3463, lr_0 = 4.6416e-04
Validation r2 = 0.896726
Epoch 10
Validation r2 = 0.907635
Epoch 11
Loss = 4.0361e-02, PNorm = 34.2036, GNorm = 1.5672, lr_0 = 3.9377e-04
Validation r2 = 0.919181
Epoch 12
Loss = 3.1749e-02, PNorm = 34.2126, GNorm = 3.1962, lr_0 = 3.3866e-04
Validation r2 = 0.919621
Epoch 13
Validation r2 = 0.924396
Epoch 14
Loss = 2.0363e-02, PNorm = 34.2190, GNorm = 0.2436, lr_0 = 2.9126e-04
Validation r2 = 0.937064
Epoch 15
Validation r2 = 0.941478
Epoch 16
Loss = 2.2169e-02, PNorm = 34.2257, GNorm = 0.7254, lr_0 = 2.4709e-04
Validation r2 = 0.941992
Epoch 17
Loss = 1.8420e-02, PNorm = 34.2305, GNorm = 1.2849, lr_0 = 2.1544e-04
Validation r2 = 0.924785
Epoch 18
Validation r2 = 0.943320
Epoch 19
Loss = 1.5132e-02, PNorm = 34.2339, GNorm = 1.2577, lr_0 = 1.8277e-04
Validation r2 = 0.932292
Epoch 20
Loss = 1.7073e-02, PNorm = 34.2364, GNorm = 0.8561, lr_0 = 1.5719e-04
Validation r2 = 0.943805
Epoch 21
Validation r2 = 0.940925
Epoch 22
Loss = 1.6229e-02, PNorm = 34.2398, GNorm = 1.5302, lr_0 = 1.3519e-04
Validation r2 = 0.950621
Epoch 23
Validation r2 = 0.950994
Epoch 24
Loss = 1.3637e-02, PNorm = 34.2419, GNorm = 0.6766, lr_0 = 1.1469e-04
Validation r2 = 0.951263
Epoch 25
Loss = 1.0752e-02, PNorm = 34.2435, GNorm = 0.6842, lr_0 = 1.0000e-04
Validation r2 = 0.953676
Epoch 26
Validation r2 = 0.954006
Epoch 27
Loss = 1.1614e-02, PNorm = 34.2455, GNorm = 0.7464, lr_0 = 1.0000e-04
Validation r2 = 0.955275
Epoch 28
Loss = 1.3119e-02, PNorm = 34.2474, GNorm = 0.6189, lr_0 = 1.0000e-04
Loss = 9.1975e-03, PNorm = 34.2476, GNorm = 0.7917, lr_0 = 1.0000e-04
Validation r2 = 0.949877
Epoch 29
Validation r2 = 0.954767
Model 0 best validation r2 = 0.955275 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.984988
Ensemble test r2 = 0.984988
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.600550
Epoch 1
Loss = 3.7305e-01, PNorm = 34.0380, GNorm = 4.0471, lr_0 = 1.0000e-03
Validation r2 = 0.722782
Epoch 2
Validation r2 = 0.703694
Epoch 3
Loss = 1.4358e-01, PNorm = 34.0912, GNorm = 1.3859, lr_0 = 8.4834e-04
Validation r2 = 0.823836
Epoch 4
Loss = 1.4428e-01, PNorm = 34.1190, GNorm = 1.3901, lr_0 = 7.2962e-04
Validation r2 = 0.859146
Epoch 5
Validation r2 = 0.894534
Epoch 6
Loss = 8.0058e-02, PNorm = 34.1417, GNorm = 1.5776, lr_0 = 6.2751e-04
Validation r2 = 0.912332
Epoch 7
Validation r2 = 0.917402
Epoch 8
Loss = 6.8895e-02, PNorm = 34.1629, GNorm = 3.0916, lr_0 = 5.3234e-04
Validation r2 = 0.933104
Epoch 9
Loss = 5.4840e-02, PNorm = 34.1760, GNorm = 3.1879, lr_0 = 4.6416e-04
Validation r2 = 0.929290
Epoch 10
Validation r2 = 0.950602
Epoch 11
Loss = 4.5203e-02, PNorm = 34.1893, GNorm = 2.5113, lr_0 = 3.9377e-04
Validation r2 = 0.950371
Epoch 12
Loss = 3.3131e-02, PNorm = 34.1986, GNorm = 1.0398, lr_0 = 3.3866e-04
Validation r2 = 0.955991
Epoch 13
Validation r2 = 0.952867
Epoch 14
Loss = 2.3628e-02, PNorm = 34.2055, GNorm = 0.5169, lr_0 = 2.9126e-04
Validation r2 = 0.960327
Epoch 15
Validation r2 = 0.965731
Epoch 16
Loss = 1.6729e-02, PNorm = 34.2116, GNorm = 1.2696, lr_0 = 2.4709e-04
Validation r2 = 0.966244
Epoch 17
Loss = 2.2852e-02, PNorm = 34.2156, GNorm = 0.3260, lr_0 = 2.1544e-04
Validation r2 = 0.969177
Epoch 18
Validation r2 = 0.970488
Epoch 19
Loss = 2.0986e-02, PNorm = 34.2200, GNorm = 0.6456, lr_0 = 1.8277e-04
Validation r2 = 0.971149
Epoch 20
Loss = 1.9108e-02, PNorm = 34.2232, GNorm = 0.7060, lr_0 = 1.5719e-04
Validation r2 = 0.972013
Epoch 21
Validation r2 = 0.968282
Epoch 22
Loss = 2.0893e-02, PNorm = 34.2259, GNorm = 1.1869, lr_0 = 1.3519e-04
Validation r2 = 0.972572
Epoch 23
Validation r2 = 0.967208
Epoch 24
Loss = 2.1023e-02, PNorm = 34.2286, GNorm = 1.8903, lr_0 = 1.1469e-04
Validation r2 = 0.965011
Epoch 25
Loss = 2.0197e-02, PNorm = 34.2306, GNorm = 0.7277, lr_0 = 1.0000e-04
Validation r2 = 0.977549
Epoch 26
Validation r2 = 0.978295
Epoch 27
Loss = 2.3994e-02, PNorm = 34.2328, GNorm = 0.6444, lr_0 = 1.0000e-04
Validation r2 = 0.979001
Epoch 28
Loss = 1.4498e-02, PNorm = 34.2348, GNorm = 0.3728, lr_0 = 1.0000e-04
Loss = 4.4235e-02, PNorm = 34.2350, GNorm = 1.6256, lr_0 = 1.0000e-04
Validation r2 = 0.978895
Epoch 29
Validation r2 = 0.977024
Model 0 best validation r2 = 0.979001 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.965575
Ensemble test r2 = 0.965575
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.320258
Epoch 1
Loss = 3.6348e-01, PNorm = 34.0356, GNorm = 4.0663, lr_0 = 1.0000e-03
Validation r2 = 0.500866
Epoch 2
Validation r2 = 0.672257
Epoch 3
Loss = 2.0102e-01, PNorm = 34.0805, GNorm = 1.1718, lr_0 = 8.4834e-04
Validation r2 = 0.742031
Epoch 4
Loss = 1.5701e-01, PNorm = 34.1086, GNorm = 1.0196, lr_0 = 7.2962e-04
Validation r2 = 0.762327
Epoch 5
Validation r2 = 0.819268
Epoch 6
Loss = 1.1482e-01, PNorm = 34.1371, GNorm = 3.9211, lr_0 = 6.2751e-04
Validation r2 = 0.884839
Epoch 7
Validation r2 = 0.897294
Epoch 8
Loss = 1.2792e-01, PNorm = 34.1575, GNorm = 1.0524, lr_0 = 5.3234e-04
Validation r2 = 0.906657
Epoch 9
Loss = 7.4187e-02, PNorm = 34.1739, GNorm = 0.4970, lr_0 = 4.6416e-04
Validation r2 = 0.939623
Epoch 10
Validation r2 = 0.936714
Epoch 11
Loss = 4.2506e-02, PNorm = 34.1898, GNorm = 0.6771, lr_0 = 3.9377e-04
Validation r2 = 0.943273
Epoch 12
Loss = 4.2591e-02, PNorm = 34.2010, GNorm = 2.1086, lr_0 = 3.3866e-04
Validation r2 = 0.940229
Epoch 13
Validation r2 = 0.955135
Epoch 14
Loss = 4.0271e-02, PNorm = 34.2095, GNorm = 3.0138, lr_0 = 2.9126e-04
Validation r2 = 0.927214
Epoch 15
Validation r2 = 0.955712
Epoch 16
Loss = 3.1943e-02, PNorm = 34.2155, GNorm = 0.9060, lr_0 = 2.4709e-04
Validation r2 = 0.955724
Epoch 17
Loss = 2.3741e-02, PNorm = 34.2209, GNorm = 0.4997, lr_0 = 2.1544e-04
Validation r2 = 0.960443
Epoch 18
Validation r2 = 0.962851
Epoch 19
Loss = 1.7346e-02, PNorm = 34.2265, GNorm = 0.6876, lr_0 = 1.8277e-04
Validation r2 = 0.966390
Epoch 20
Loss = 2.2248e-02, PNorm = 34.2306, GNorm = 0.5047, lr_0 = 1.5719e-04
Validation r2 = 0.964770
Epoch 21
Validation r2 = 0.965140
Epoch 22
Loss = 1.6916e-02, PNorm = 34.2333, GNorm = 0.8523, lr_0 = 1.3519e-04
Validation r2 = 0.966179
Epoch 23
Validation r2 = 0.967900
Epoch 24
Loss = 1.6713e-02, PNorm = 34.2360, GNorm = 1.3916, lr_0 = 1.1469e-04
Validation r2 = 0.967194
Epoch 25
Loss = 1.5279e-02, PNorm = 34.2382, GNorm = 1.1411, lr_0 = 1.0000e-04
Validation r2 = 0.969833
Epoch 26
Validation r2 = 0.966265
Epoch 27
Loss = 1.8870e-02, PNorm = 34.2401, GNorm = 0.6127, lr_0 = 1.0000e-04
Validation r2 = 0.970476
Epoch 28
Loss = 1.7129e-02, PNorm = 34.2416, GNorm = 0.3120, lr_0 = 1.0000e-04
Loss = 2.4059e-02, PNorm = 34.2418, GNorm = 1.7847, lr_0 = 1.0000e-04
Validation r2 = 0.967311
Epoch 29
Validation r2 = 0.970725
Model 0 best validation r2 = 0.970725 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.976152
Ensemble test r2 = 0.976152
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.550045
Epoch 1
Loss = 4.6429e-01, PNorm = 34.0363, GNorm = 4.3415, lr_0 = 1.0000e-03
Validation r2 = 0.767209
Epoch 2
Validation r2 = 0.834706
Epoch 3
Loss = 1.7557e-01, PNorm = 34.0811, GNorm = 1.0197, lr_0 = 8.4834e-04
Validation r2 = 0.866294
Epoch 4
Loss = 1.5640e-01, PNorm = 34.1123, GNorm = 2.7805, lr_0 = 7.2962e-04
Validation r2 = 0.874475
Epoch 5
Validation r2 = 0.910864
Epoch 6
Loss = 1.1123e-01, PNorm = 34.1401, GNorm = 0.5744, lr_0 = 6.2751e-04
Validation r2 = 0.921602
Epoch 7
Validation r2 = 0.935116
Epoch 8
Loss = 7.7614e-02, PNorm = 34.1661, GNorm = 0.6865, lr_0 = 5.3234e-04
Validation r2 = 0.944148
Epoch 9
Loss = 5.4041e-02, PNorm = 34.1838, GNorm = 1.3418, lr_0 = 4.6416e-04
Validation r2 = 0.938472
Epoch 10
Validation r2 = 0.955335
Epoch 11
Loss = 4.7097e-02, PNorm = 34.1957, GNorm = 4.5539, lr_0 = 3.9377e-04
Validation r2 = 0.932431
Epoch 12
Loss = 5.6615e-02, PNorm = 34.2048, GNorm = 3.8230, lr_0 = 3.3866e-04
Validation r2 = 0.967725
Epoch 13
Validation r2 = 0.962657
Epoch 14
Loss = 3.6112e-02, PNorm = 34.2124, GNorm = 1.6932, lr_0 = 2.9126e-04
Validation r2 = 0.963834
Epoch 15
Validation r2 = 0.965320
Epoch 16
Loss = 3.3403e-02, PNorm = 34.2199, GNorm = 1.1806, lr_0 = 2.4709e-04
Validation r2 = 0.968527
Epoch 17
Loss = 2.4763e-02, PNorm = 34.2249, GNorm = 0.7020, lr_0 = 2.1544e-04
Validation r2 = 0.967532
Epoch 18
Validation r2 = 0.968035
Epoch 19
Loss = 2.0723e-02, PNorm = 34.2294, GNorm = 0.6583, lr_0 = 1.8277e-04
Validation r2 = 0.968036
Epoch 20
Loss = 1.8998e-02, PNorm = 34.2329, GNorm = 0.3751, lr_0 = 1.5719e-04
Validation r2 = 0.970850
Epoch 21
Validation r2 = 0.970736
Epoch 22
Loss = 1.7906e-02, PNorm = 34.2358, GNorm = 0.1906, lr_0 = 1.3519e-04
Validation r2 = 0.970232
Epoch 23
Validation r2 = 0.971255
Epoch 24
Loss = 2.5433e-02, PNorm = 34.2387, GNorm = 0.2526, lr_0 = 1.1469e-04
Validation r2 = 0.970063
Epoch 25
Loss = 1.7791e-02, PNorm = 34.2406, GNorm = 0.6430, lr_0 = 1.0000e-04
Validation r2 = 0.970275
Epoch 26
Validation r2 = 0.972080
Epoch 27
Loss = 1.5250e-02, PNorm = 34.2429, GNorm = 0.9804, lr_0 = 1.0000e-04
Validation r2 = 0.972021
Epoch 28
Loss = 1.6483e-02, PNorm = 34.2458, GNorm = 0.5621, lr_0 = 1.0000e-04
Loss = 7.1196e-03, PNorm = 34.2460, GNorm = 1.3939, lr_0 = 1.0000e-04
Validation r2 = 0.970571
Epoch 29
Validation r2 = 0.971335
Model 0 best validation r2 = 0.972080 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.961520
Ensemble test r2 = 0.961520
5-fold cross validation
	Seed 0 ==> test r2 = 0.940272
	Seed 1 ==> test r2 = 0.984988
	Seed 2 ==> test r2 = 0.965575
	Seed 3 ==> test r2 = 0.976152
	Seed 4 ==> test r2 = 0.961520
Overall test r2 = 0.965701 +/- 0.015135
Elapsed time = 0:01:55
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484D2X6CM7Ean3d.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.269621
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation rmse = 0.180477
Epoch 2
Validation rmse = 0.175057
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation rmse = 0.155382
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation rmse = 0.152049
Epoch 5
Validation rmse = 0.127462
Epoch 6
Loss = 9.1617e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation rmse = 0.124463
Epoch 7
Validation rmse = 0.109621
Epoch 8
Loss = 2.7033e-02, PNorm = 34.1663, GNorm = 1.5388, lr_0 = 5.3234e-04
Validation rmse = 0.100677
Epoch 9
Loss = 6.0310e-02, PNorm = 34.1833, GNorm = 1.1763, lr_0 = 4.6416e-04
Validation rmse = 0.096233
Epoch 10
Validation rmse = 0.088408
Epoch 11
Loss = 4.8576e-02, PNorm = 34.1980, GNorm = 3.0190, lr_0 = 3.9377e-04
Validation rmse = 0.088261
Epoch 12
Loss = 4.0376e-02, PNorm = 34.2081, GNorm = 2.1901, lr_0 = 3.3866e-04
Validation rmse = 0.072880
Epoch 13
Validation rmse = 0.074117
Epoch 14
Loss = 2.9638e-02, PNorm = 34.2176, GNorm = 1.5122, lr_0 = 2.9126e-04
Validation rmse = 0.075204
Epoch 15
Validation rmse = 0.067249
Epoch 16
Loss = 2.7263e-02, PNorm = 34.2254, GNorm = 0.4222, lr_0 = 2.4709e-04
Validation rmse = 0.064966
Epoch 17
Loss = 1.3779e-02, PNorm = 34.2301, GNorm = 0.8317, lr_0 = 2.1544e-04
Validation rmse = 0.063238
Epoch 18
Validation rmse = 0.062209
Epoch 19
Loss = 2.2177e-02, PNorm = 34.2347, GNorm = 1.1778, lr_0 = 1.8277e-04
Validation rmse = 0.061001
Epoch 20
Loss = 2.1519e-02, PNorm = 34.2381, GNorm = 1.5615, lr_0 = 1.5719e-04
Validation rmse = 0.060365
Epoch 21
Validation rmse = 0.063118
Epoch 22
Loss = 1.7815e-02, PNorm = 34.2411, GNorm = 0.7914, lr_0 = 1.3519e-04
Validation rmse = 0.058431
Epoch 23
Validation rmse = 0.059245
Epoch 24
Loss = 1.4564e-02, PNorm = 34.2439, GNorm = 0.4033, lr_0 = 1.1469e-04
Validation rmse = 0.057316
Epoch 25
Loss = 1.8541e-02, PNorm = 34.2460, GNorm = 1.4425, lr_0 = 1.0000e-04
Validation rmse = 0.057688
Epoch 26
Validation rmse = 0.059294
Epoch 27
Loss = 1.4505e-02, PNorm = 34.2485, GNorm = 0.2266, lr_0 = 1.0000e-04
Validation rmse = 0.057366
Epoch 28
Loss = 1.6110e-02, PNorm = 34.2508, GNorm = 0.6797, lr_0 = 1.0000e-04
Loss = 1.1988e-02, PNorm = 34.2509, GNorm = 0.6031, lr_0 = 1.0000e-04
Validation rmse = 0.055100
Epoch 29
Validation rmse = 0.056154
Model 0 best validation rmse = 0.055100 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.100295
Ensemble test rmse = 0.100295
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.165141
Epoch 1
Loss = 4.1795e-01, PNorm = 34.0376, GNorm = 1.5927, lr_0 = 1.0000e-03
Validation rmse = 0.141351
Epoch 2
Validation rmse = 0.129071
Epoch 3
Loss = 1.5872e-01, PNorm = 34.0896, GNorm = 2.2771, lr_0 = 8.4834e-04
Validation rmse = 0.155226
Epoch 4
Loss = 1.4736e-01, PNorm = 34.1228, GNorm = 0.7535, lr_0 = 7.2962e-04
Validation rmse = 0.129522
Epoch 5
Validation rmse = 0.105419
Epoch 6
Loss = 9.2302e-02, PNorm = 34.1491, GNorm = 1.6146, lr_0 = 6.2751e-04
Validation rmse = 0.098700
Epoch 7
Validation rmse = 0.108479
Epoch 8
Loss = 6.9239e-02, PNorm = 34.1743, GNorm = 3.3022, lr_0 = 5.3234e-04
Validation rmse = 0.086171
Epoch 9
Loss = 4.1668e-02, PNorm = 34.1901, GNorm = 0.3463, lr_0 = 4.6416e-04
Validation rmse = 0.084850
Epoch 10
Validation rmse = 0.080244
Epoch 11
Loss = 4.0361e-02, PNorm = 34.2036, GNorm = 1.5672, lr_0 = 3.9377e-04
Validation rmse = 0.075061
Epoch 12
Loss = 3.1749e-02, PNorm = 34.2126, GNorm = 3.1962, lr_0 = 3.3866e-04
Validation rmse = 0.074857
Epoch 13
Validation rmse = 0.072599
Epoch 14
Loss = 2.0363e-02, PNorm = 34.2190, GNorm = 0.2436, lr_0 = 2.9126e-04
Validation rmse = 0.066238
Epoch 15
Validation rmse = 0.063873
Epoch 16
Loss = 2.2169e-02, PNorm = 34.2257, GNorm = 0.7254, lr_0 = 2.4709e-04
Validation rmse = 0.063592
Epoch 17
Loss = 1.8420e-02, PNorm = 34.2305, GNorm = 1.2849, lr_0 = 2.1544e-04
Validation rmse = 0.072412
Epoch 18
Validation rmse = 0.062860
Epoch 19
Loss = 1.5132e-02, PNorm = 34.2339, GNorm = 1.2577, lr_0 = 1.8277e-04
Validation rmse = 0.068704
Epoch 20
Loss = 1.7073e-02, PNorm = 34.2364, GNorm = 0.8561, lr_0 = 1.5719e-04
Validation rmse = 0.062590
Epoch 21
Validation rmse = 0.064174
Epoch 22
Loss = 1.6229e-02, PNorm = 34.2398, GNorm = 1.5302, lr_0 = 1.3519e-04
Validation rmse = 0.058672
Epoch 23
Validation rmse = 0.058450
Epoch 24
Loss = 1.3637e-02, PNorm = 34.2419, GNorm = 0.6766, lr_0 = 1.1469e-04
Validation rmse = 0.058289
Epoch 25
Loss = 1.0752e-02, PNorm = 34.2435, GNorm = 0.6842, lr_0 = 1.0000e-04
Validation rmse = 0.056828
Epoch 26
Validation rmse = 0.056625
Epoch 27
Loss = 1.1614e-02, PNorm = 34.2455, GNorm = 0.7464, lr_0 = 1.0000e-04
Validation rmse = 0.055838
Epoch 28
Loss = 1.3119e-02, PNorm = 34.2474, GNorm = 0.6189, lr_0 = 1.0000e-04
Loss = 9.1975e-03, PNorm = 34.2476, GNorm = 0.7917, lr_0 = 1.0000e-04
Validation rmse = 0.059112
Epoch 29
Validation rmse = 0.056155
Model 0 best validation rmse = 0.055838 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.050819
Ensemble test rmse = 0.050819
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.198698
Epoch 1
Loss = 3.7305e-01, PNorm = 34.0380, GNorm = 4.0471, lr_0 = 1.0000e-03
Validation rmse = 0.165529
Epoch 2
Validation rmse = 0.171133
Epoch 3
Loss = 1.4358e-01, PNorm = 34.0912, GNorm = 1.3859, lr_0 = 8.4834e-04
Validation rmse = 0.131954
Epoch 4
Loss = 1.4428e-01, PNorm = 34.1190, GNorm = 1.3901, lr_0 = 7.2962e-04
Validation rmse = 0.117991
Epoch 5
Validation rmse = 0.102099
Epoch 6
Loss = 8.0058e-02, PNorm = 34.1417, GNorm = 1.5776, lr_0 = 6.2751e-04
Validation rmse = 0.093086
Epoch 7
Validation rmse = 0.090354
Epoch 8
Loss = 6.8895e-02, PNorm = 34.1629, GNorm = 3.0916, lr_0 = 5.3234e-04
Validation rmse = 0.081313
Epoch 9
Loss = 5.4840e-02, PNorm = 34.1760, GNorm = 3.1879, lr_0 = 4.6416e-04
Validation rmse = 0.083599
Epoch 10
Validation rmse = 0.069874
Epoch 11
Loss = 4.5203e-02, PNorm = 34.1893, GNorm = 2.5113, lr_0 = 3.9377e-04
Validation rmse = 0.070037
Epoch 12
Loss = 3.3131e-02, PNorm = 34.1986, GNorm = 1.0398, lr_0 = 3.3866e-04
Validation rmse = 0.065953
Epoch 13
Validation rmse = 0.068254
Epoch 14
Loss = 2.3628e-02, PNorm = 34.2055, GNorm = 0.5169, lr_0 = 2.9126e-04
Validation rmse = 0.062620
Epoch 15
Validation rmse = 0.058199
Epoch 16
Loss = 1.6729e-02, PNorm = 34.2116, GNorm = 1.2696, lr_0 = 2.4709e-04
Validation rmse = 0.057762
Epoch 17
Loss = 2.2852e-02, PNorm = 34.2156, GNorm = 0.3260, lr_0 = 2.1544e-04
Validation rmse = 0.055195
Epoch 18
Validation rmse = 0.054008
Epoch 19
Loss = 2.0986e-02, PNorm = 34.2200, GNorm = 0.6456, lr_0 = 1.8277e-04
Validation rmse = 0.053400
Epoch 20
Loss = 1.9108e-02, PNorm = 34.2232, GNorm = 0.7060, lr_0 = 1.5719e-04
Validation rmse = 0.052595
Epoch 21
Validation rmse = 0.055991
Epoch 22
Loss = 2.0893e-02, PNorm = 34.2259, GNorm = 1.1869, lr_0 = 1.3519e-04
Validation rmse = 0.052067
Epoch 23
Validation rmse = 0.056932
Epoch 24
Loss = 2.1024e-02, PNorm = 34.2286, GNorm = 1.8905, lr_0 = 1.1469e-04
Validation rmse = 0.058807
Epoch 25
Loss = 2.0197e-02, PNorm = 34.2306, GNorm = 0.7268, lr_0 = 1.0000e-04
Validation rmse = 0.047108
Epoch 26
Validation rmse = 0.046320
Epoch 27
Loss = 2.3995e-02, PNorm = 34.2328, GNorm = 0.6444, lr_0 = 1.0000e-04
Validation rmse = 0.045562
Epoch 28
Loss = 1.4499e-02, PNorm = 34.2348, GNorm = 0.3727, lr_0 = 1.0000e-04
Loss = 4.4230e-02, PNorm = 34.2350, GNorm = 1.6247, lr_0 = 1.0000e-04
Validation rmse = 0.045682
Epoch 29
Validation rmse = 0.047655
Model 0 best validation rmse = 0.045562 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.055898
Ensemble test rmse = 0.055898
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.270396
Epoch 1
Loss = 3.6348e-01, PNorm = 34.0356, GNorm = 4.0663, lr_0 = 1.0000e-03
Validation rmse = 0.231706
Epoch 2
Validation rmse = 0.187757
Epoch 3
Loss = 2.0102e-01, PNorm = 34.0805, GNorm = 1.1718, lr_0 = 8.4834e-04
Validation rmse = 0.166576
Epoch 4
Loss = 1.5701e-01, PNorm = 34.1086, GNorm = 1.0196, lr_0 = 7.2962e-04
Validation rmse = 0.159889
Epoch 5
Validation rmse = 0.139427
Epoch 6
Loss = 1.1482e-01, PNorm = 34.1371, GNorm = 3.9211, lr_0 = 6.2751e-04
Validation rmse = 0.111297
Epoch 7
Validation rmse = 0.105106
Epoch 8
Loss = 1.2792e-01, PNorm = 34.1575, GNorm = 1.0524, lr_0 = 5.3234e-04
Validation rmse = 0.100201
Epoch 9
Loss = 7.4187e-02, PNorm = 34.1739, GNorm = 0.4970, lr_0 = 4.6416e-04
Validation rmse = 0.080587
Epoch 10
Validation rmse = 0.082505
Epoch 11
Loss = 4.2506e-02, PNorm = 34.1898, GNorm = 0.6771, lr_0 = 3.9377e-04
Validation rmse = 0.078113
Epoch 12
Loss = 4.2591e-02, PNorm = 34.2010, GNorm = 2.1086, lr_0 = 3.3866e-04
Validation rmse = 0.080181
Epoch 13
Validation rmse = 0.069468
Epoch 14
Loss = 4.0271e-02, PNorm = 34.2095, GNorm = 3.0138, lr_0 = 2.9126e-04
Validation rmse = 0.088481
Epoch 15
Validation rmse = 0.069020
Epoch 16
Loss = 3.1943e-02, PNorm = 34.2155, GNorm = 0.9060, lr_0 = 2.4709e-04
Validation rmse = 0.069010
Epoch 17
Loss = 2.3741e-02, PNorm = 34.2209, GNorm = 0.4997, lr_0 = 2.1544e-04
Validation rmse = 0.065229
Epoch 18
Validation rmse = 0.063212
Epoch 19
Loss = 1.7347e-02, PNorm = 34.2265, GNorm = 0.6876, lr_0 = 1.8277e-04
Validation rmse = 0.060127
Epoch 20
Loss = 2.2248e-02, PNorm = 34.2306, GNorm = 0.5047, lr_0 = 1.5719e-04
Validation rmse = 0.061558
Epoch 21
Validation rmse = 0.061234
Epoch 22
Loss = 1.6916e-02, PNorm = 34.2333, GNorm = 0.8523, lr_0 = 1.3519e-04
Validation rmse = 0.060315
Epoch 23
Validation rmse = 0.058760
Epoch 24
Loss = 1.6713e-02, PNorm = 34.2360, GNorm = 1.3916, lr_0 = 1.1469e-04
Validation rmse = 0.059403
Epoch 25
Loss = 1.5279e-02, PNorm = 34.2382, GNorm = 1.1411, lr_0 = 1.0000e-04
Validation rmse = 0.056963
Epoch 26
Validation rmse = 0.060237
Epoch 27
Loss = 1.8870e-02, PNorm = 34.2401, GNorm = 0.6127, lr_0 = 1.0000e-04
Validation rmse = 0.056353
Epoch 28
Loss = 1.7129e-02, PNorm = 34.2416, GNorm = 0.3121, lr_0 = 1.0000e-04
Loss = 2.4059e-02, PNorm = 34.2418, GNorm = 1.7847, lr_0 = 1.0000e-04
Validation rmse = 0.059296
Epoch 29
Validation rmse = 0.056115
Model 0 best validation rmse = 0.056115 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.056670
Ensemble test rmse = 0.056670
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation rmse = 0.233935
Epoch 1
Loss = 4.6429e-01, PNorm = 34.0363, GNorm = 4.3415, lr_0 = 1.0000e-03
Validation rmse = 0.168265
Epoch 2
Validation rmse = 0.141788
Epoch 3
Loss = 1.7557e-01, PNorm = 34.0811, GNorm = 1.0197, lr_0 = 8.4834e-04
Validation rmse = 0.127522
Epoch 4
Loss = 1.5640e-01, PNorm = 34.1123, GNorm = 2.7805, lr_0 = 7.2962e-04
Validation rmse = 0.123559
Epoch 5
Validation rmse = 0.104121
Epoch 6
Loss = 1.1123e-01, PNorm = 34.1401, GNorm = 0.5744, lr_0 = 6.2751e-04
Validation rmse = 0.097648
Epoch 7
Validation rmse = 0.088834
Epoch 8
Loss = 7.7614e-02, PNorm = 34.1661, GNorm = 0.6865, lr_0 = 5.3234e-04
Validation rmse = 0.082419
Epoch 9
Loss = 5.4041e-02, PNorm = 34.1838, GNorm = 1.3418, lr_0 = 4.6416e-04
Validation rmse = 0.086506
Epoch 10
Validation rmse = 0.073704
Epoch 11
Loss = 4.7097e-02, PNorm = 34.1957, GNorm = 4.5539, lr_0 = 3.9377e-04
Validation rmse = 0.090654
Epoch 12
Loss = 5.6615e-02, PNorm = 34.2048, GNorm = 3.8230, lr_0 = 3.3866e-04
Validation rmse = 0.062653
Epoch 13
Validation rmse = 0.067393
Epoch 14
Loss = 3.6112e-02, PNorm = 34.2124, GNorm = 1.6932, lr_0 = 2.9126e-04
Validation rmse = 0.066322
Epoch 15
Validation rmse = 0.064946
Epoch 16
Loss = 3.3403e-02, PNorm = 34.2199, GNorm = 1.1806, lr_0 = 2.4709e-04
Validation rmse = 0.061870
Epoch 17
Loss = 2.4763e-02, PNorm = 34.2249, GNorm = 0.7020, lr_0 = 2.1544e-04
Validation rmse = 0.062841
Epoch 18
Validation rmse = 0.062351
Epoch 19
Loss = 2.0723e-02, PNorm = 34.2294, GNorm = 0.6583, lr_0 = 1.8277e-04
Validation rmse = 0.062351
Epoch 20
Loss = 1.8998e-02, PNorm = 34.2329, GNorm = 0.3751, lr_0 = 1.5719e-04
Validation rmse = 0.059542
Epoch 21
Validation rmse = 0.059659
Epoch 22
Loss = 1.7906e-02, PNorm = 34.2358, GNorm = 0.1906, lr_0 = 1.3519e-04
Validation rmse = 0.060171
Epoch 23
Validation rmse = 0.059128
Epoch 24
Loss = 2.5433e-02, PNorm = 34.2387, GNorm = 0.2526, lr_0 = 1.1469e-04
Validation rmse = 0.060341
Epoch 25
Loss = 1.7791e-02, PNorm = 34.2406, GNorm = 0.6430, lr_0 = 1.0000e-04
Validation rmse = 0.060127
Epoch 26
Validation rmse = 0.058273
Epoch 27
Loss = 1.5250e-02, PNorm = 34.2429, GNorm = 0.9804, lr_0 = 1.0000e-04
Validation rmse = 0.058335
Epoch 28
Loss = 1.6483e-02, PNorm = 34.2458, GNorm = 0.5621, lr_0 = 1.0000e-04
Loss = 7.1196e-03, PNorm = 34.2460, GNorm = 1.3939, lr_0 = 1.0000e-04
Validation rmse = 0.059827
Epoch 29
Validation rmse = 0.059045
Model 0 best validation rmse = 0.058273 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.067995
Ensemble test rmse = 0.067995
5-fold cross validation
	Seed 0 ==> test rmse = 0.100295
	Seed 1 ==> test rmse = 0.050819
	Seed 2 ==> test rmse = 0.055898
	Seed 3 ==> test rmse = 0.056670
	Seed 4 ==> test rmse = 0.067995
Overall test rmse = 0.066335 +/- 0.017884
Elapsed time = 0:02:17
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484D2X6CM7Ean3d.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.490594
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation r2 = 0.771756
Epoch 2
Validation r2 = 0.785258
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation r2 = 0.830818
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation r2 = 0.837998
Epoch 5
Validation r2 = 0.886153
Epoch 6
Loss = 9.1617e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation r2 = 0.891449
Epoch 7
Validation r2 = 0.915794
Epoch 8
Loss = 2.7033e-02, PNorm = 34.1663, GNorm = 1.5388, lr_0 = 5.3234e-04
Validation r2 = 0.928974
Epoch 9
Loss = 6.0310e-02, PNorm = 34.1833, GNorm = 1.1763, lr_0 = 4.6416e-04
Validation r2 = 0.935106
Epoch 10
Validation r2 = 0.945230
Epoch 11
Loss = 4.8576e-02, PNorm = 34.1980, GNorm = 3.0190, lr_0 = 3.9377e-04
Validation r2 = 0.945413
Epoch 12
Loss = 4.0376e-02, PNorm = 34.2081, GNorm = 2.1901, lr_0 = 3.3866e-04
Validation r2 = 0.962781
Epoch 13
Validation r2 = 0.961506
Epoch 14
Loss = 2.9638e-02, PNorm = 34.2176, GNorm = 1.5122, lr_0 = 2.9126e-04
Validation r2 = 0.960369
Epoch 15
Validation r2 = 0.968309
Epoch 16
Loss = 2.7263e-02, PNorm = 34.2254, GNorm = 0.4222, lr_0 = 2.4709e-04
Validation r2 = 0.970425
Epoch 17
Loss = 1.3779e-02, PNorm = 34.2301, GNorm = 0.8317, lr_0 = 2.1544e-04
Validation r2 = 0.971977
Epoch 18
Validation r2 = 0.972882
Epoch 19
Loss = 2.2177e-02, PNorm = 34.2347, GNorm = 1.1778, lr_0 = 1.8277e-04
Validation r2 = 0.973925
Epoch 20
Loss = 2.1519e-02, PNorm = 34.2381, GNorm = 1.5615, lr_0 = 1.5719e-04
Validation r2 = 0.974466
Epoch 21
Validation r2 = 0.972083
Epoch 22
Loss = 1.7815e-02, PNorm = 34.2411, GNorm = 0.7914, lr_0 = 1.3519e-04
Validation r2 = 0.976076
Epoch 23
Validation r2 = 0.975405
Epoch 24
Loss = 1.4564e-02, PNorm = 34.2439, GNorm = 0.4033, lr_0 = 1.1469e-04
Validation r2 = 0.976980
Epoch 25
Loss = 1.8541e-02, PNorm = 34.2460, GNorm = 1.4425, lr_0 = 1.0000e-04
Validation r2 = 0.976680
Epoch 26
Validation r2 = 0.975363
Epoch 27
Loss = 1.4505e-02, PNorm = 34.2485, GNorm = 0.2266, lr_0 = 1.0000e-04
Validation r2 = 0.976939
Epoch 28
Loss = 1.6110e-02, PNorm = 34.2508, GNorm = 0.6797, lr_0 = 1.0000e-04
Loss = 1.1988e-02, PNorm = 34.2509, GNorm = 0.6031, lr_0 = 1.0000e-04
Validation r2 = 0.978725
Epoch 29
Validation r2 = 0.977904
Model 0 best validation r2 = 0.978725 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.940206
Ensemble test r2 = 0.940206
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.608807
Epoch 1
Loss = 4.1795e-01, PNorm = 34.0376, GNorm = 1.5927, lr_0 = 1.0000e-03
Validation r2 = 0.713398
Epoch 2
Validation r2 = 0.761033
Epoch 3
Loss = 1.5872e-01, PNorm = 34.0896, GNorm = 2.2771, lr_0 = 8.4834e-04
Validation r2 = 0.654372
Epoch 4
Loss = 1.4736e-01, PNorm = 34.1228, GNorm = 0.7535, lr_0 = 7.2962e-04
Validation r2 = 0.759359
Epoch 5
Validation r2 = 0.840587
Epoch 6
Loss = 9.2302e-02, PNorm = 34.1491, GNorm = 1.6146, lr_0 = 6.2751e-04
Validation r2 = 0.860262
Epoch 7
Validation r2 = 0.831200
Epoch 8
Loss = 6.9239e-02, PNorm = 34.1743, GNorm = 3.3022, lr_0 = 5.3234e-04
Validation r2 = 0.893487
Epoch 9
Loss = 4.1668e-02, PNorm = 34.1901, GNorm = 0.3463, lr_0 = 4.6416e-04
Validation r2 = 0.896726
Epoch 10
Validation r2 = 0.907635
Epoch 11
Loss = 4.0362e-02, PNorm = 34.2036, GNorm = 1.5672, lr_0 = 3.9377e-04
Validation r2 = 0.919181
Epoch 12
Loss = 3.1749e-02, PNorm = 34.2126, GNorm = 3.1962, lr_0 = 3.3866e-04
Validation r2 = 0.919621
Epoch 13
Validation r2 = 0.924396
Epoch 14
Loss = 2.0363e-02, PNorm = 34.2190, GNorm = 0.2436, lr_0 = 2.9126e-04
Validation r2 = 0.937064
Epoch 15
Validation r2 = 0.941478
Epoch 16
Loss = 2.2169e-02, PNorm = 34.2257, GNorm = 0.7254, lr_0 = 2.4709e-04
Validation r2 = 0.941992
Epoch 17
Loss = 1.8420e-02, PNorm = 34.2305, GNorm = 1.2849, lr_0 = 2.1544e-04
Validation r2 = 0.924785
Epoch 18
Validation r2 = 0.943321
Epoch 19
Loss = 1.5132e-02, PNorm = 34.2339, GNorm = 1.2577, lr_0 = 1.8277e-04
Validation r2 = 0.932292
Epoch 20
Loss = 1.7072e-02, PNorm = 34.2364, GNorm = 0.8539, lr_0 = 1.5719e-04
Validation r2 = 0.943791
Epoch 21
Validation r2 = 0.940930
Epoch 22
Loss = 1.6235e-02, PNorm = 34.2398, GNorm = 1.5317, lr_0 = 1.3519e-04
Validation r2 = 0.950638
Epoch 23
Validation r2 = 0.951013
Epoch 24
Loss = 1.3636e-02, PNorm = 34.2419, GNorm = 0.6779, lr_0 = 1.1469e-04
Validation r2 = 0.951275
Epoch 25
Loss = 1.0752e-02, PNorm = 34.2435, GNorm = 0.6840, lr_0 = 1.0000e-04
Validation r2 = 0.953693
Epoch 26
Validation r2 = 0.954019
Epoch 27
Loss = 1.1611e-02, PNorm = 34.2455, GNorm = 0.7466, lr_0 = 1.0000e-04
Validation r2 = 0.955283
Epoch 28
Loss = 1.3117e-02, PNorm = 34.2474, GNorm = 0.6208, lr_0 = 1.0000e-04
Loss = 9.1865e-03, PNorm = 34.2476, GNorm = 0.7897, lr_0 = 1.0000e-04
Validation r2 = 0.949914
Epoch 29
Validation r2 = 0.954782
Model 0 best validation r2 = 0.955283 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.984995
Ensemble test r2 = 0.984995
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.600550
Epoch 1
Loss = 3.7305e-01, PNorm = 34.0380, GNorm = 4.0471, lr_0 = 1.0000e-03
Validation r2 = 0.722782
Epoch 2
Validation r2 = 0.703694
Epoch 3
Loss = 1.4358e-01, PNorm = 34.0912, GNorm = 1.3859, lr_0 = 8.4834e-04
Validation r2 = 0.823836
Epoch 4
Loss = 1.4428e-01, PNorm = 34.1190, GNorm = 1.3901, lr_0 = 7.2962e-04
Validation r2 = 0.859146
Epoch 5
Validation r2 = 0.894534
Epoch 6
Loss = 8.0058e-02, PNorm = 34.1417, GNorm = 1.5776, lr_0 = 6.2751e-04
Validation r2 = 0.912332
Epoch 7
Validation r2 = 0.917402
Epoch 8
Loss = 6.8895e-02, PNorm = 34.1629, GNorm = 3.0916, lr_0 = 5.3234e-04
Validation r2 = 0.933104
Epoch 9
Loss = 5.4840e-02, PNorm = 34.1760, GNorm = 3.1879, lr_0 = 4.6416e-04
Validation r2 = 0.929290
Epoch 10
Validation r2 = 0.950602
Epoch 11
Loss = 4.5203e-02, PNorm = 34.1893, GNorm = 2.5113, lr_0 = 3.9377e-04
Validation r2 = 0.950371
Epoch 12
Loss = 3.3131e-02, PNorm = 34.1986, GNorm = 1.0398, lr_0 = 3.3866e-04
Validation r2 = 0.955991
Epoch 13
Validation r2 = 0.952867
Epoch 14
Loss = 2.3628e-02, PNorm = 34.2055, GNorm = 0.5169, lr_0 = 2.9126e-04
Validation r2 = 0.960327
Epoch 15
Validation r2 = 0.965731
Epoch 16
Loss = 1.6729e-02, PNorm = 34.2116, GNorm = 1.2696, lr_0 = 2.4709e-04
Validation r2 = 0.966244
Epoch 17
Loss = 2.2852e-02, PNorm = 34.2156, GNorm = 0.3260, lr_0 = 2.1544e-04
Validation r2 = 0.969177
Epoch 18
Validation r2 = 0.970488
Epoch 19
Loss = 2.0986e-02, PNorm = 34.2200, GNorm = 0.6456, lr_0 = 1.8277e-04
Validation r2 = 0.971149
Epoch 20
Loss = 1.9108e-02, PNorm = 34.2232, GNorm = 0.7060, lr_0 = 1.5719e-04
Validation r2 = 0.972013
Epoch 21
Validation r2 = 0.968282
Epoch 22
Loss = 2.0893e-02, PNorm = 34.2259, GNorm = 1.1869, lr_0 = 1.3519e-04
Validation r2 = 0.972572
Epoch 23
Validation r2 = 0.967208
Epoch 24
Loss = 2.1023e-02, PNorm = 34.2286, GNorm = 1.8903, lr_0 = 1.1469e-04
Validation r2 = 0.965011
Epoch 25
Loss = 2.0197e-02, PNorm = 34.2306, GNorm = 0.7277, lr_0 = 1.0000e-04
Validation r2 = 0.977549
Epoch 26
Validation r2 = 0.978295
Epoch 27
Loss = 2.3994e-02, PNorm = 34.2328, GNorm = 0.6443, lr_0 = 1.0000e-04
Validation r2 = 0.979001
Epoch 28
Loss = 1.4498e-02, PNorm = 34.2348, GNorm = 0.3728, lr_0 = 1.0000e-04
Loss = 4.4235e-02, PNorm = 34.2350, GNorm = 1.6257, lr_0 = 1.0000e-04
Validation r2 = 0.978894
Epoch 29
Validation r2 = 0.977023
Model 0 best validation r2 = 0.979001 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.965575
Ensemble test r2 = 0.965575
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.320258
Epoch 1
Loss = 3.6348e-01, PNorm = 34.0356, GNorm = 4.0663, lr_0 = 1.0000e-03
Validation r2 = 0.500866
Epoch 2
Validation r2 = 0.672257
Epoch 3
Loss = 2.0102e-01, PNorm = 34.0805, GNorm = 1.1718, lr_0 = 8.4834e-04
Validation r2 = 0.742031
Epoch 4
Loss = 1.5701e-01, PNorm = 34.1086, GNorm = 1.0196, lr_0 = 7.2962e-04
Validation r2 = 0.762328
Epoch 5
Validation r2 = 0.819268
Epoch 6
Loss = 1.1482e-01, PNorm = 34.1371, GNorm = 3.9211, lr_0 = 6.2751e-04
Validation r2 = 0.884839
Epoch 7
Validation r2 = 0.897294
Epoch 8
Loss = 1.2792e-01, PNorm = 34.1575, GNorm = 1.0524, lr_0 = 5.3234e-04
Validation r2 = 0.906657
Epoch 9
Loss = 7.4187e-02, PNorm = 34.1739, GNorm = 0.4970, lr_0 = 4.6416e-04
Validation r2 = 0.939623
Epoch 10
Validation r2 = 0.936714
Epoch 11
Loss = 4.2506e-02, PNorm = 34.1898, GNorm = 0.6771, lr_0 = 3.9377e-04
Validation r2 = 0.943273
Epoch 12
Loss = 4.2591e-02, PNorm = 34.2010, GNorm = 2.1086, lr_0 = 3.3866e-04
Validation r2 = 0.940229
Epoch 13
Validation r2 = 0.955135
Epoch 14
Loss = 4.0271e-02, PNorm = 34.2095, GNorm = 3.0138, lr_0 = 2.9126e-04
Validation r2 = 0.927214
Epoch 15
Validation r2 = 0.955712
Epoch 16
Loss = 3.1943e-02, PNorm = 34.2155, GNorm = 0.9060, lr_0 = 2.4709e-04
Validation r2 = 0.955724
Epoch 17
Loss = 2.3741e-02, PNorm = 34.2209, GNorm = 0.4997, lr_0 = 2.1544e-04
Validation r2 = 0.960443
Epoch 18
Validation r2 = 0.962851
Epoch 19
Loss = 1.7347e-02, PNorm = 34.2265, GNorm = 0.6876, lr_0 = 1.8277e-04
Validation r2 = 0.966390
Epoch 20
Loss = 2.2248e-02, PNorm = 34.2306, GNorm = 0.5047, lr_0 = 1.5719e-04
Validation r2 = 0.964770
Epoch 21
Validation r2 = 0.965140
Epoch 22
Loss = 1.6916e-02, PNorm = 34.2333, GNorm = 0.8523, lr_0 = 1.3519e-04
Validation r2 = 0.966179
Epoch 23
Validation r2 = 0.967900
Epoch 24
Loss = 1.6713e-02, PNorm = 34.2360, GNorm = 1.3916, lr_0 = 1.1469e-04
Validation r2 = 0.967194
Epoch 25
Loss = 1.5279e-02, PNorm = 34.2382, GNorm = 1.1411, lr_0 = 1.0000e-04
Validation r2 = 0.969833
Epoch 26
Validation r2 = 0.966266
Epoch 27
Loss = 1.8870e-02, PNorm = 34.2401, GNorm = 0.6127, lr_0 = 1.0000e-04
Validation r2 = 0.970476
Epoch 28
Loss = 1.7129e-02, PNorm = 34.2416, GNorm = 0.3120, lr_0 = 1.0000e-04
Loss = 2.4059e-02, PNorm = 34.2418, GNorm = 1.7847, lr_0 = 1.0000e-04
Validation r2 = 0.967311
Epoch 29
Validation r2 = 0.970725
Model 0 best validation r2 = 0.970725 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.976152
Ensemble test r2 = 0.976152
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.550045
Epoch 1
Loss = 4.6429e-01, PNorm = 34.0363, GNorm = 4.3415, lr_0 = 1.0000e-03
Validation r2 = 0.767209
Epoch 2
Validation r2 = 0.834706
Epoch 3
Loss = 1.7557e-01, PNorm = 34.0811, GNorm = 1.0197, lr_0 = 8.4834e-04
Validation r2 = 0.866294
Epoch 4
Loss = 1.5640e-01, PNorm = 34.1123, GNorm = 2.7805, lr_0 = 7.2962e-04
Validation r2 = 0.874475
Epoch 5
Validation r2 = 0.910864
Epoch 6
Loss = 1.1123e-01, PNorm = 34.1401, GNorm = 0.5744, lr_0 = 6.2751e-04
Validation r2 = 0.921602
Epoch 7
Validation r2 = 0.935116
Epoch 8
Loss = 7.7614e-02, PNorm = 34.1661, GNorm = 0.6865, lr_0 = 5.3234e-04
Validation r2 = 0.944148
Epoch 9
Loss = 5.4041e-02, PNorm = 34.1838, GNorm = 1.3418, lr_0 = 4.6416e-04
Validation r2 = 0.938472
Epoch 10
Validation r2 = 0.955335
Epoch 11
Loss = 4.7097e-02, PNorm = 34.1957, GNorm = 4.5539, lr_0 = 3.9377e-04
Validation r2 = 0.932431
Epoch 12
Loss = 5.6615e-02, PNorm = 34.2048, GNorm = 3.8230, lr_0 = 3.3866e-04
Validation r2 = 0.967725
Epoch 13
Validation r2 = 0.962657
Epoch 14
Loss = 3.6112e-02, PNorm = 34.2124, GNorm = 1.6932, lr_0 = 2.9126e-04
Validation r2 = 0.963834
Epoch 15
Validation r2 = 0.965320
Epoch 16
Loss = 3.3403e-02, PNorm = 34.2199, GNorm = 1.1806, lr_0 = 2.4709e-04
Validation r2 = 0.968527
Epoch 17
Loss = 2.4763e-02, PNorm = 34.2249, GNorm = 0.7020, lr_0 = 2.1544e-04
Validation r2 = 0.967532
Epoch 18
Validation r2 = 0.968035
Epoch 19
Loss = 2.0723e-02, PNorm = 34.2294, GNorm = 0.6583, lr_0 = 1.8277e-04
Validation r2 = 0.968036
Epoch 20
Loss = 1.8998e-02, PNorm = 34.2329, GNorm = 0.3751, lr_0 = 1.5719e-04
Validation r2 = 0.970850
Epoch 21
Validation r2 = 0.970736
Epoch 22
Loss = 1.7906e-02, PNorm = 34.2358, GNorm = 0.1906, lr_0 = 1.3519e-04
Validation r2 = 0.970232
Epoch 23
Validation r2 = 0.971255
Epoch 24
Loss = 2.5433e-02, PNorm = 34.2387, GNorm = 0.2526, lr_0 = 1.1469e-04
Validation r2 = 0.970063
Epoch 25
Loss = 1.7791e-02, PNorm = 34.2406, GNorm = 0.6430, lr_0 = 1.0000e-04
Validation r2 = 0.970276
Epoch 26
Validation r2 = 0.972080
Epoch 27
Loss = 1.5250e-02, PNorm = 34.2429, GNorm = 0.9803, lr_0 = 1.0000e-04
Validation r2 = 0.972021
Epoch 28
Loss = 1.6483e-02, PNorm = 34.2458, GNorm = 0.5620, lr_0 = 1.0000e-04
Loss = 7.1184e-03, PNorm = 34.2460, GNorm = 1.3936, lr_0 = 1.0000e-04
Validation r2 = 0.970572
Epoch 29
Validation r2 = 0.971336
Model 0 best validation r2 = 0.972080 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.961521
Ensemble test r2 = 0.961521
5-fold cross validation
	Seed 0 ==> test r2 = 0.940206
	Seed 1 ==> test r2 = 0.984995
	Seed 2 ==> test r2 = 0.965575
	Seed 3 ==> test r2 = 0.976152
	Seed 4 ==> test r2 = 0.961521
Overall test r2 = 0.965690 +/- 0.015159
Elapsed time = 0:02:49
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484j1bpz5duhRfl.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.490594
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation r2 = 0.771756
Epoch 2
Validation r2 = 0.785258
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation r2 = 0.830818
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation r2 = 0.837998
Epoch 5
Validation r2 = 0.886153
Epoch 6
Loss = 9.1617e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation r2 = 0.891449
Epoch 7
Validation r2 = 0.915794
Epoch 8
Loss = 2.7033e-02, PNorm = 34.1663, GNorm = 1.5388, lr_0 = 5.3234e-04
Validation r2 = 0.928974
Epoch 9
Loss = 6.0310e-02, PNorm = 34.1833, GNorm = 1.1763, lr_0 = 4.6416e-04
Validation r2 = 0.935106
Epoch 10
Validation r2 = 0.945230
Epoch 11
Loss = 4.8576e-02, PNorm = 34.1980, GNorm = 3.0190, lr_0 = 3.9377e-04
Validation r2 = 0.945413
Epoch 12
Loss = 4.0376e-02, PNorm = 34.2081, GNorm = 2.1901, lr_0 = 3.3866e-04
Validation r2 = 0.962781
Epoch 13
Validation r2 = 0.961506
Epoch 14
Loss = 2.9638e-02, PNorm = 34.2176, GNorm = 1.5122, lr_0 = 2.9126e-04
Validation r2 = 0.960369
Epoch 15
Validation r2 = 0.968309
Epoch 16
Loss = 2.7263e-02, PNorm = 34.2254, GNorm = 0.4222, lr_0 = 2.4709e-04
Validation r2 = 0.970425
Epoch 17
Loss = 1.3779e-02, PNorm = 34.2301, GNorm = 0.8317, lr_0 = 2.1544e-04
Validation r2 = 0.971977
Epoch 18
Validation r2 = 0.972882
Epoch 19
Loss = 2.2177e-02, PNorm = 34.2347, GNorm = 1.1778, lr_0 = 1.8277e-04
Validation r2 = 0.973925
Epoch 20
Loss = 2.1519e-02, PNorm = 34.2381, GNorm = 1.5615, lr_0 = 1.5719e-04
Validation r2 = 0.974466
Epoch 21
Validation r2 = 0.972083
Epoch 22
Loss = 1.7815e-02, PNorm = 34.2411, GNorm = 0.7914, lr_0 = 1.3519e-04
Validation r2 = 0.976076
Epoch 23
Validation r2 = 0.975405
Epoch 24
Loss = 1.4564e-02, PNorm = 34.2439, GNorm = 0.4033, lr_0 = 1.1469e-04
Validation r2 = 0.976980
Epoch 25
Loss = 1.8541e-02, PNorm = 34.2460, GNorm = 1.4425, lr_0 = 1.0000e-04
Validation r2 = 0.976680
Epoch 26
Validation r2 = 0.975363
Epoch 27
Loss = 1.4505e-02, PNorm = 34.2485, GNorm = 0.2266, lr_0 = 1.0000e-04
Validation r2 = 0.976939
Epoch 28
Loss = 1.6110e-02, PNorm = 34.2508, GNorm = 0.6797, lr_0 = 1.0000e-04
Loss = 1.1988e-02, PNorm = 34.2509, GNorm = 0.6031, lr_0 = 1.0000e-04
Validation r2 = 0.978725
Epoch 29
Validation r2 = 0.977904
Model 0 best validation r2 = 0.978725 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.940206
Ensemble test r2 = 0.940206
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.608807
Epoch 1
Loss = 4.1795e-01, PNorm = 34.0376, GNorm = 1.5927, lr_0 = 1.0000e-03
Validation r2 = 0.713398
Epoch 2
Validation r2 = 0.761033
Epoch 3
Loss = 1.5872e-01, PNorm = 34.0896, GNorm = 2.2771, lr_0 = 8.4834e-04
Validation r2 = 0.654372
Epoch 4
Loss = 1.4736e-01, PNorm = 34.1228, GNorm = 0.7535, lr_0 = 7.2962e-04
Validation r2 = 0.759359
Epoch 5
Validation r2 = 0.840587
Epoch 6
Loss = 9.2302e-02, PNorm = 34.1491, GNorm = 1.6146, lr_0 = 6.2751e-04
Validation r2 = 0.860262
Epoch 7
Validation r2 = 0.831200
Epoch 8
Loss = 6.9239e-02, PNorm = 34.1743, GNorm = 3.3022, lr_0 = 5.3234e-04
Validation r2 = 0.893487
Epoch 9
Loss = 4.1668e-02, PNorm = 34.1901, GNorm = 0.3463, lr_0 = 4.6416e-04
Validation r2 = 0.896726
Epoch 10
Validation r2 = 0.907635
Epoch 11
Loss = 4.0361e-02, PNorm = 34.2036, GNorm = 1.5672, lr_0 = 3.9377e-04
Validation r2 = 0.919181
Epoch 12
Loss = 3.1749e-02, PNorm = 34.2126, GNorm = 3.1962, lr_0 = 3.3866e-04
Validation r2 = 0.919621
Epoch 13
Validation r2 = 0.924396
Epoch 14
Loss = 2.0363e-02, PNorm = 34.2190, GNorm = 0.2436, lr_0 = 2.9126e-04
Validation r2 = 0.937064
Epoch 15
Validation r2 = 0.941478
Epoch 16
Loss = 2.2169e-02, PNorm = 34.2257, GNorm = 0.7254, lr_0 = 2.4709e-04
Validation r2 = 0.941992
Epoch 17
Loss = 1.8420e-02, PNorm = 34.2305, GNorm = 1.2849, lr_0 = 2.1544e-04
Validation r2 = 0.924785
Epoch 18
Validation r2 = 0.943320
Epoch 19
Loss = 1.5132e-02, PNorm = 34.2339, GNorm = 1.2577, lr_0 = 1.8277e-04
Validation r2 = 0.932292
Epoch 20
Loss = 1.7073e-02, PNorm = 34.2364, GNorm = 0.8561, lr_0 = 1.5719e-04
Validation r2 = 0.943805
Epoch 21
Validation r2 = 0.940925
Epoch 22
Loss = 1.6229e-02, PNorm = 34.2398, GNorm = 1.5302, lr_0 = 1.3519e-04
Validation r2 = 0.950621
Epoch 23
Validation r2 = 0.950994
Epoch 24
Loss = 1.3637e-02, PNorm = 34.2419, GNorm = 0.6766, lr_0 = 1.1469e-04
Validation r2 = 0.951263
Epoch 25
Loss = 1.0752e-02, PNorm = 34.2435, GNorm = 0.6842, lr_0 = 1.0000e-04
Validation r2 = 0.953676
Epoch 26
Validation r2 = 0.954006
Epoch 27
Loss = 1.1614e-02, PNorm = 34.2455, GNorm = 0.7464, lr_0 = 1.0000e-04
Validation r2 = 0.955275
Epoch 28
Loss = 1.3119e-02, PNorm = 34.2474, GNorm = 0.6189, lr_0 = 1.0000e-04
Loss = 9.1975e-03, PNorm = 34.2476, GNorm = 0.7917, lr_0 = 1.0000e-04
Validation r2 = 0.949877
Epoch 29
Validation r2 = 0.954767
Model 0 best validation r2 = 0.955275 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.984988
Ensemble test r2 = 0.984988
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.600550
Epoch 1
Loss = 3.7305e-01, PNorm = 34.0380, GNorm = 4.0471, lr_0 = 1.0000e-03
Validation r2 = 0.722782
Epoch 2
Validation r2 = 0.703694
Epoch 3
Loss = 1.4358e-01, PNorm = 34.0912, GNorm = 1.3859, lr_0 = 8.4834e-04
Validation r2 = 0.823836
Epoch 4
Loss = 1.4428e-01, PNorm = 34.1190, GNorm = 1.3901, lr_0 = 7.2962e-04
Validation r2 = 0.859146
Epoch 5
Validation r2 = 0.894534
Epoch 6
Loss = 8.0058e-02, PNorm = 34.1417, GNorm = 1.5776, lr_0 = 6.2751e-04
Validation r2 = 0.912332
Epoch 7
Validation r2 = 0.917402
Epoch 8
Loss = 6.8895e-02, PNorm = 34.1629, GNorm = 3.0916, lr_0 = 5.3234e-04
Validation r2 = 0.933104
Epoch 9
Loss = 5.4840e-02, PNorm = 34.1760, GNorm = 3.1879, lr_0 = 4.6416e-04
Validation r2 = 0.929290
Epoch 10
Validation r2 = 0.950602
Epoch 11
Loss = 4.5203e-02, PNorm = 34.1893, GNorm = 2.5113, lr_0 = 3.9377e-04
Validation r2 = 0.950371
Epoch 12
Loss = 3.3131e-02, PNorm = 34.1986, GNorm = 1.0398, lr_0 = 3.3866e-04
Validation r2 = 0.955991
Epoch 13
Validation r2 = 0.952867
Epoch 14
Loss = 2.3628e-02, PNorm = 34.2055, GNorm = 0.5169, lr_0 = 2.9126e-04
Validation r2 = 0.960327
Epoch 15
Validation r2 = 0.965731
Epoch 16
Loss = 1.6729e-02, PNorm = 34.2116, GNorm = 1.2696, lr_0 = 2.4709e-04
Validation r2 = 0.966244
Epoch 17
Loss = 2.2852e-02, PNorm = 34.2156, GNorm = 0.3260, lr_0 = 2.1544e-04
Validation r2 = 0.969177
Epoch 18
Validation r2 = 0.970488
Epoch 19
Loss = 2.0986e-02, PNorm = 34.2200, GNorm = 0.6456, lr_0 = 1.8277e-04
Validation r2 = 0.971149
Epoch 20
Loss = 1.9108e-02, PNorm = 34.2232, GNorm = 0.7060, lr_0 = 1.5719e-04
Validation r2 = 0.972013
Epoch 21
Validation r2 = 0.968282
Epoch 22
Loss = 2.0893e-02, PNorm = 34.2259, GNorm = 1.1869, lr_0 = 1.3519e-04
Validation r2 = 0.972572
Epoch 23
Validation r2 = 0.967208
Epoch 24
Loss = 2.1023e-02, PNorm = 34.2286, GNorm = 1.8903, lr_0 = 1.1469e-04
Validation r2 = 0.965011
Epoch 25
Loss = 2.0197e-02, PNorm = 34.2306, GNorm = 0.7277, lr_0 = 1.0000e-04
Validation r2 = 0.977549
Epoch 26
Validation r2 = 0.978295
Epoch 27
Loss = 2.3994e-02, PNorm = 34.2328, GNorm = 0.6443, lr_0 = 1.0000e-04
Validation r2 = 0.979001
Epoch 28
Loss = 1.4498e-02, PNorm = 34.2348, GNorm = 0.3728, lr_0 = 1.0000e-04
Loss = 4.4235e-02, PNorm = 34.2350, GNorm = 1.6257, lr_0 = 1.0000e-04
Validation r2 = 0.978894
Epoch 29
Validation r2 = 0.977023
Model 0 best validation r2 = 0.979001 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.965575
Ensemble test r2 = 0.965575
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.320258
Epoch 1
Loss = 3.6348e-01, PNorm = 34.0356, GNorm = 4.0663, lr_0 = 1.0000e-03
Validation r2 = 0.500866
Epoch 2
Validation r2 = 0.672257
Epoch 3
Loss = 2.0102e-01, PNorm = 34.0805, GNorm = 1.1718, lr_0 = 8.4834e-04
Validation r2 = 0.742031
Epoch 4
Loss = 1.5701e-01, PNorm = 34.1086, GNorm = 1.0196, lr_0 = 7.2962e-04
Validation r2 = 0.762327
Epoch 5
Validation r2 = 0.819268
Epoch 6
Loss = 1.1482e-01, PNorm = 34.1371, GNorm = 3.9211, lr_0 = 6.2751e-04
Validation r2 = 0.884839
Epoch 7
Validation r2 = 0.897294
Epoch 8
Loss = 1.2792e-01, PNorm = 34.1575, GNorm = 1.0524, lr_0 = 5.3234e-04
Validation r2 = 0.906657
Epoch 9
Loss = 7.4187e-02, PNorm = 34.1739, GNorm = 0.4970, lr_0 = 4.6416e-04
Validation r2 = 0.939623
Epoch 10
Validation r2 = 0.936714
Epoch 11
Loss = 4.2506e-02, PNorm = 34.1898, GNorm = 0.6771, lr_0 = 3.9377e-04
Validation r2 = 0.943273
Epoch 12
Loss = 4.2591e-02, PNorm = 34.2010, GNorm = 2.1086, lr_0 = 3.3866e-04
Validation r2 = 0.940229
Epoch 13
Validation r2 = 0.955135
Epoch 14
Loss = 4.0271e-02, PNorm = 34.2095, GNorm = 3.0138, lr_0 = 2.9126e-04
Validation r2 = 0.927214
Epoch 15
Validation r2 = 0.955712
Epoch 16
Loss = 3.1943e-02, PNorm = 34.2155, GNorm = 0.9060, lr_0 = 2.4709e-04
Validation r2 = 0.955724
Epoch 17
Loss = 2.3741e-02, PNorm = 34.2209, GNorm = 0.4997, lr_0 = 2.1544e-04
Validation r2 = 0.960443
Epoch 18
Validation r2 = 0.962851
Epoch 19
Loss = 1.7346e-02, PNorm = 34.2265, GNorm = 0.6876, lr_0 = 1.8277e-04
Validation r2 = 0.966390
Epoch 20
Loss = 2.2248e-02, PNorm = 34.2306, GNorm = 0.5047, lr_0 = 1.5719e-04
Validation r2 = 0.964770
Epoch 21
Validation r2 = 0.965140
Epoch 22
Loss = 1.6916e-02, PNorm = 34.2333, GNorm = 0.8523, lr_0 = 1.3519e-04
Validation r2 = 0.966179
Epoch 23
Validation r2 = 0.967900
Epoch 24
Loss = 1.6713e-02, PNorm = 34.2360, GNorm = 1.3916, lr_0 = 1.1469e-04
Validation r2 = 0.967194
Epoch 25
Loss = 1.5279e-02, PNorm = 34.2382, GNorm = 1.1411, lr_0 = 1.0000e-04
Validation r2 = 0.969833
Epoch 26
Validation r2 = 0.966265
Epoch 27
Loss = 1.8870e-02, PNorm = 34.2401, GNorm = 0.6127, lr_0 = 1.0000e-04
Validation r2 = 0.970476
Epoch 28
Loss = 1.7129e-02, PNorm = 34.2416, GNorm = 0.3120, lr_0 = 1.0000e-04
Loss = 2.4059e-02, PNorm = 34.2418, GNorm = 1.7847, lr_0 = 1.0000e-04
Validation r2 = 0.967311
Epoch 29
Validation r2 = 0.970725
Model 0 best validation r2 = 0.970725 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.976152
Ensemble test r2 = 0.976152
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.550045
Epoch 1
Loss = 4.6429e-01, PNorm = 34.0363, GNorm = 4.3415, lr_0 = 1.0000e-03
Validation r2 = 0.767209
Epoch 2
Validation r2 = 0.834706
Epoch 3
Loss = 1.7557e-01, PNorm = 34.0811, GNorm = 1.0197, lr_0 = 8.4834e-04
Validation r2 = 0.866294
Epoch 4
Loss = 1.5640e-01, PNorm = 34.1123, GNorm = 2.7805, lr_0 = 7.2962e-04
Validation r2 = 0.874475
Epoch 5
Validation r2 = 0.910864
Epoch 6
Loss = 1.1123e-01, PNorm = 34.1401, GNorm = 0.5744, lr_0 = 6.2751e-04
Validation r2 = 0.921602
Epoch 7
Validation r2 = 0.935116
Epoch 8
Loss = 7.7614e-02, PNorm = 34.1661, GNorm = 0.6865, lr_0 = 5.3234e-04
Validation r2 = 0.944148
Epoch 9
Loss = 5.4041e-02, PNorm = 34.1838, GNorm = 1.3418, lr_0 = 4.6416e-04
Validation r2 = 0.938472
Epoch 10
Validation r2 = 0.955335
Epoch 11
Loss = 4.7097e-02, PNorm = 34.1957, GNorm = 4.5539, lr_0 = 3.9377e-04
Validation r2 = 0.932431
Epoch 12
Loss = 5.6615e-02, PNorm = 34.2048, GNorm = 3.8230, lr_0 = 3.3866e-04
Validation r2 = 0.967725
Epoch 13
Validation r2 = 0.962657
Epoch 14
Loss = 3.6112e-02, PNorm = 34.2124, GNorm = 1.6932, lr_0 = 2.9126e-04
Validation r2 = 0.963834
Epoch 15
Validation r2 = 0.965320
Epoch 16
Loss = 3.3403e-02, PNorm = 34.2199, GNorm = 1.1806, lr_0 = 2.4709e-04
Validation r2 = 0.968527
Epoch 17
Loss = 2.4763e-02, PNorm = 34.2249, GNorm = 0.7020, lr_0 = 2.1544e-04
Validation r2 = 0.967532
Epoch 18
Validation r2 = 0.968035
Epoch 19
Loss = 2.0723e-02, PNorm = 34.2294, GNorm = 0.6583, lr_0 = 1.8277e-04
Validation r2 = 0.968036
Epoch 20
Loss = 1.8998e-02, PNorm = 34.2329, GNorm = 0.3751, lr_0 = 1.5719e-04
Validation r2 = 0.970850
Epoch 21
Validation r2 = 0.970736
Epoch 22
Loss = 1.7906e-02, PNorm = 34.2358, GNorm = 0.1906, lr_0 = 1.3519e-04
Validation r2 = 0.970232
Epoch 23
Validation r2 = 0.971255
Epoch 24
Loss = 2.5433e-02, PNorm = 34.2387, GNorm = 0.2526, lr_0 = 1.1469e-04
Validation r2 = 0.970063
Epoch 25
Loss = 1.7791e-02, PNorm = 34.2406, GNorm = 0.6430, lr_0 = 1.0000e-04
Validation r2 = 0.970275
Epoch 26
Validation r2 = 0.972080
Epoch 27
Loss = 1.5250e-02, PNorm = 34.2429, GNorm = 0.9804, lr_0 = 1.0000e-04
Validation r2 = 0.972021
Epoch 28
Loss = 1.6483e-02, PNorm = 34.2458, GNorm = 0.5621, lr_0 = 1.0000e-04
Loss = 7.1196e-03, PNorm = 34.2460, GNorm = 1.3939, lr_0 = 1.0000e-04
Validation r2 = 0.970571
Epoch 29
Validation r2 = 0.971335
Model 0 best validation r2 = 0.972080 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.961520
Ensemble test r2 = 0.961520
5-fold cross validation
	Seed 0 ==> test r2 = 0.940206
	Seed 1 ==> test r2 = 0.984988
	Seed 2 ==> test r2 = 0.965575
	Seed 3 ==> test r2 = 0.976152
	Seed 4 ==> test r2 = 0.961520
Overall test r2 = 0.965688 +/- 0.015157
Elapsed time = 0:02:13
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484j1bpz5duhRfl.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.490594
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation r2 = 0.771756
Epoch 2
Validation r2 = 0.785258
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation r2 = 0.830818
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation r2 = 0.837998
Epoch 5
Validation r2 = 0.886154
Epoch 6
Loss = 9.1618e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation r2 = 0.891456
Epoch 7
Validation r2 = 0.915790
Epoch 8
Loss = 2.7049e-02, PNorm = 34.1663, GNorm = 1.5414, lr_0 = 5.3234e-04
Validation r2 = 0.928989
Epoch 9
Loss = 6.0311e-02, PNorm = 34.1834, GNorm = 1.1713, lr_0 = 4.6416e-04
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-10484j1bpz5duhRfl.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../csv_files/Polymers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.490594
Epoch 1
Loss = 4.9524e-01, PNorm = 34.0367, GNorm = 5.8949, lr_0 = 1.0000e-03
Validation r2 = 0.771756
Epoch 2
Validation r2 = 0.785258
Epoch 3
Loss = 1.9783e-01, PNorm = 34.0841, GNorm = 0.5301, lr_0 = 8.4834e-04
Validation r2 = 0.830818
Epoch 4
Loss = 1.5894e-01, PNorm = 34.1166, GNorm = 0.6723, lr_0 = 7.2962e-04
Validation r2 = 0.837998
Epoch 5
Validation r2 = 0.886153
Epoch 6
Loss = 9.1617e-02, PNorm = 34.1410, GNorm = 0.6622, lr_0 = 6.2751e-04
Validation r2 = 0.891449
Epoch 7
Validation r2 = 0.915794
Epoch 8
Loss = 2.7033e-02, PNorm = 34.1663, GNorm = 1.5388, lr_0 = 5.3234e-04
Validation r2 = 0.928974
Epoch 9
Loss = 6.0310e-02, PNorm = 34.1833, GNorm = 1.1763, lr_0 = 4.6416e-04
Validation r2 = 0.935106
Epoch 10
Validation r2 = 0.945230
Epoch 11
Loss = 4.8576e-02, PNorm = 34.1980, GNorm = 3.0190, lr_0 = 3.9377e-04
Validation r2 = 0.945413
Epoch 12
Loss = 4.0376e-02, PNorm = 34.2081, GNorm = 2.1901, lr_0 = 3.3866e-04
Validation r2 = 0.962781
Epoch 13
Validation r2 = 0.961506
Epoch 14
Loss = 2.9638e-02, PNorm = 34.2176, GNorm = 1.5122, lr_0 = 2.9126e-04
Validation r2 = 0.960369
Epoch 15
Validation r2 = 0.968310
Epoch 16
Loss = 2.7262e-02, PNorm = 34.2254, GNorm = 0.4222, lr_0 = 2.4709e-04
Validation r2 = 0.970425
Epoch 17
Loss = 1.3779e-02, PNorm = 34.2301, GNorm = 0.8317, lr_0 = 2.1544e-04
Validation r2 = 0.971977
Epoch 18
Validation r2 = 0.972882
Epoch 19
Loss = 2.2175e-02, PNorm = 34.2347, GNorm = 1.1779, lr_0 = 1.8277e-04
Validation r2 = 0.973924
Epoch 20
Loss = 2.1519e-02, PNorm = 34.2381, GNorm = 1.5620, lr_0 = 1.5719e-04
Validation r2 = 0.974465
Epoch 21
Validation r2 = 0.972077
Epoch 22
Loss = 1.7816e-02, PNorm = 34.2411, GNorm = 0.7911, lr_0 = 1.3519e-04
Validation r2 = 0.976073
Epoch 23
Validation r2 = 0.975401
Epoch 24
Loss = 1.4563e-02, PNorm = 34.2439, GNorm = 0.4038, lr_0 = 1.1469e-04
Validation r2 = 0.976979
Epoch 25
Loss = 1.8540e-02, PNorm = 34.2460, GNorm = 1.4413, lr_0 = 1.0000e-04
Validation r2 = 0.976692
Epoch 26
Validation r2 = 0.975364
Epoch 27
Loss = 1.4511e-02, PNorm = 34.2485, GNorm = 0.2267, lr_0 = 1.0000e-04
Validation r2 = 0.976941
Epoch 28
Loss = 1.6109e-02, PNorm = 34.2508, GNorm = 0.6791, lr_0 = 1.0000e-04
Loss = 1.1993e-02, PNorm = 34.2509, GNorm = 0.6033, lr_0 = 1.0000e-04
Validation r2 = 0.978713
Epoch 29
Validation r2 = 0.977904
Model 0 best validation r2 = 0.978713 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.940210
Ensemble test r2 = 0.940210
1-fold cross validation
	Seed 0 ==> test r2 = 0.940210
Overall test r2 = 0.940210 +/- 0.000000
Elapsed time = 0:00:33
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-7548MTB3pczK8W0I.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../csv_files/Trimers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.543962
Epoch 1
Loss = 4.7373e-01, PNorm = 34.0357, GNorm = 6.2279, lr_0 = 1.0000e-03
Validation r2 = 0.797164
Epoch 2
Validation r2 = 0.770890
Epoch 3
Loss = 1.9245e-01, PNorm = 34.0808, GNorm = 1.2893, lr_0 = 8.4834e-04
Validation r2 = 0.846408
Epoch 4
Loss = 1.3923e-01, PNorm = 34.1082, GNorm = 1.5660, lr_0 = 7.2962e-04
Validation r2 = 0.864467
Epoch 5
Validation r2 = 0.913658
Epoch 6
Loss = 7.2040e-02, PNorm = 34.1327, GNorm = 2.1795, lr_0 = 6.2751e-04
Validation r2 = 0.923094
Epoch 7
Validation r2 = 0.932987
Epoch 8
Loss = 1.6376e-02, PNorm = 34.1559, GNorm = 0.7651, lr_0 = 5.3234e-04
Validation r2 = 0.945132
Epoch 9
Loss = 4.1296e-02, PNorm = 34.1714, GNorm = 0.5314, lr_0 = 4.6416e-04
Validation r2 = 0.947925
Epoch 10
Validation r2 = 0.957428
Epoch 11
Loss = 3.0462e-02, PNorm = 34.1844, GNorm = 2.5821, lr_0 = 3.9377e-04
Validation r2 = 0.953780
Epoch 12
Loss = 2.8507e-02, PNorm = 34.1932, GNorm = 2.5113, lr_0 = 3.3866e-04
Validation r2 = 0.968616
Epoch 13
Validation r2 = 0.969373
Epoch 14
Loss = 1.6678e-02, PNorm = 34.2010, GNorm = 0.3163, lr_0 = 2.9126e-04
Validation r2 = 0.971230
Epoch 15
Validation r2 = 0.976432
Epoch 16
Loss = 1.5161e-02, PNorm = 34.2073, GNorm = 0.4136, lr_0 = 2.4709e-04
Validation r2 = 0.978143
Epoch 17
Loss = 7.5593e-03, PNorm = 34.2110, GNorm = 0.4078, lr_0 = 2.1544e-04
Validation r2 = 0.979508
Epoch 18
Validation r2 = 0.980519
Epoch 19
Loss = 1.3736e-02, PNorm = 34.2145, GNorm = 1.3123, lr_0 = 1.8277e-04
Validation r2 = 0.980453
Epoch 20
Loss = 1.2404e-02, PNorm = 34.2176, GNorm = 1.0242, lr_0 = 1.5719e-04
Validation r2 = 0.979732
Epoch 21
Validation r2 = 0.979386
Epoch 22
Loss = 1.1755e-02, PNorm = 34.2202, GNorm = 0.1261, lr_0 = 1.3519e-04
Validation r2 = 0.983370
Epoch 23
Validation r2 = 0.980568
Epoch 24
Loss = 7.6786e-03, PNorm = 34.2227, GNorm = 0.6640, lr_0 = 1.1469e-04
Validation r2 = 0.983932
Epoch 25
Loss = 1.1838e-02, PNorm = 34.2245, GNorm = 1.5067, lr_0 = 1.0000e-04
Validation r2 = 0.984334
Epoch 26
Validation r2 = 0.981822
Epoch 27
Loss = 9.2231e-03, PNorm = 34.2267, GNorm = 0.1902, lr_0 = 1.0000e-04
Validation r2 = 0.984601
Epoch 28
Loss = 8.5813e-03, PNorm = 34.2287, GNorm = 0.6603, lr_0 = 1.0000e-04
Loss = 1.0802e-02, PNorm = 34.2288, GNorm = 0.2578, lr_0 = 1.0000e-04
Validation r2 = 0.985388
Epoch 29
Validation r2 = 0.984679
Model 0 best validation r2 = 0.985388 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.936652
Ensemble test r2 = 0.936652
1-fold cross validation
	Seed 0 ==> test r2 = 0.936652
Overall test r2 = 0.936652 +/- 0.000000
Elapsed time = 0:00:53
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-7548MTB3pczK8W0I.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../csv_files/Trimers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.543962
Epoch 1
Loss = 4.7373e-01, PNorm = 34.0357, GNorm = 6.2279, lr_0 = 1.0000e-03
Validation r2 = 0.797164
Epoch 2
Validation r2 = 0.770890
Epoch 3
Loss = 1.9245e-01, PNorm = 34.0808, GNorm = 1.2893, lr_0 = 8.4834e-04
Validation r2 = 0.846408
Epoch 4
Loss = 1.3923e-01, PNorm = 34.1082, GNorm = 1.5660, lr_0 = 7.2962e-04
Validation r2 = 0.864467
Epoch 5
Validation r2 = 0.913658
Epoch 6
Loss = 7.2040e-02, PNorm = 34.1327, GNorm = 2.1795, lr_0 = 6.2751e-04
Validation r2 = 0.923094
Epoch 7
Validation r2 = 0.932987
Epoch 8
Loss = 1.6376e-02, PNorm = 34.1559, GNorm = 0.7651, lr_0 = 5.3234e-04
Validation r2 = 0.945132
Epoch 9
Loss = 4.1296e-02, PNorm = 34.1714, GNorm = 0.5314, lr_0 = 4.6416e-04
Validation r2 = 0.947925
Epoch 10
Validation r2 = 0.957428
Epoch 11
Loss = 3.0462e-02, PNorm = 34.1844, GNorm = 2.5821, lr_0 = 3.9377e-04
Validation r2 = 0.953780
Epoch 12
Loss = 2.8507e-02, PNorm = 34.1932, GNorm = 2.5113, lr_0 = 3.3866e-04
Validation r2 = 0.968616
Epoch 13
Validation r2 = 0.969373
Epoch 14
Loss = 1.6678e-02, PNorm = 34.2010, GNorm = 0.3163, lr_0 = 2.9126e-04
Validation r2 = 0.971230
Epoch 15
Validation r2 = 0.976432
Epoch 16
Loss = 1.5161e-02, PNorm = 34.2073, GNorm = 0.4136, lr_0 = 2.4709e-04
Validation r2 = 0.978143
Epoch 17
Loss = 7.5593e-03, PNorm = 34.2110, GNorm = 0.4078, lr_0 = 2.1544e-04
Validation r2 = 0.979508
Epoch 18
Validation r2 = 0.980519
Epoch 19
Loss = 1.3736e-02, PNorm = 34.2145, GNorm = 1.3123, lr_0 = 1.8277e-04
Validation r2 = 0.980453
Epoch 20
Loss = 1.2404e-02, PNorm = 34.2176, GNorm = 1.0242, lr_0 = 1.5719e-04
Validation r2 = 0.979732
Epoch 21
Validation r2 = 0.979386
Epoch 22
Loss = 1.1755e-02, PNorm = 34.2202, GNorm = 0.1261, lr_0 = 1.3519e-04
Validation r2 = 0.983370
Epoch 23
Validation r2 = 0.980568
Epoch 24
Loss = 7.6786e-03, PNorm = 34.2227, GNorm = 0.6640, lr_0 = 1.1469e-04
Validation r2 = 0.983932
Epoch 25
Loss = 1.1838e-02, PNorm = 34.2245, GNorm = 1.5067, lr_0 = 1.0000e-04
Validation r2 = 0.984334
Epoch 26
Validation r2 = 0.981822
Epoch 27
Loss = 9.2231e-03, PNorm = 34.2267, GNorm = 0.1902, lr_0 = 1.0000e-04
Validation r2 = 0.984601
Epoch 28
Loss = 8.5813e-03, PNorm = 34.2287, GNorm = 0.6603, lr_0 = 1.0000e-04
Loss = 1.0802e-02, PNorm = 34.2288, GNorm = 0.2578, lr_0 = 1.0000e-04
Validation r2 = 0.985388
Epoch 29
Validation r2 = 0.984679
Model 0 best validation r2 = 0.985388 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.936652
Ensemble test r2 = 0.936652
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.678855
Epoch 1
Loss = 4.0609e-01, PNorm = 34.0365, GNorm = 1.9368, lr_0 = 1.0000e-03
Validation r2 = 0.765773
Epoch 2
Validation r2 = 0.826563
Epoch 3
Loss = 1.3259e-01, PNorm = 34.0875, GNorm = 1.2401, lr_0 = 8.4834e-04
Validation r2 = 0.609971
Epoch 4
Loss = 1.4120e-01, PNorm = 34.1200, GNorm = 2.2627, lr_0 = 7.2962e-04
Validation r2 = 0.774270
Epoch 5
Validation r2 = 0.850510
Epoch 6
Loss = 8.0233e-02, PNorm = 34.1450, GNorm = 0.7506, lr_0 = 6.2751e-04
Validation r2 = 0.857110
Epoch 7
Validation r2 = 0.921203
Epoch 8
Loss = 4.7481e-02, PNorm = 34.1689, GNorm = 1.7296, lr_0 = 5.3234e-04
Validation r2 = 0.932248
Epoch 9
Loss = 2.9667e-02, PNorm = 34.1850, GNorm = 1.6332, lr_0 = 4.6416e-04
Validation r2 = 0.937949
Epoch 10
Validation r2 = 0.941657
Epoch 11
Loss = 2.7763e-02, PNorm = 34.1946, GNorm = 0.7262, lr_0 = 3.9377e-04
Validation r2 = 0.948831
Epoch 12
Loss = 1.6949e-02, PNorm = 34.2013, GNorm = 0.4391, lr_0 = 3.3866e-04
Validation r2 = 0.948890
Epoch 13
Validation r2 = 0.946409
Epoch 14
Loss = 1.4171e-02, PNorm = 34.2071, GNorm = 0.2471, lr_0 = 2.9126e-04
Validation r2 = 0.956297
Epoch 15
Validation r2 = 0.959425
Epoch 16
Loss = 1.6893e-02, PNorm = 34.2123, GNorm = 0.5474, lr_0 = 2.4709e-04
Validation r2 = 0.962591
Epoch 17
Loss = 1.0863e-02, PNorm = 34.2161, GNorm = 0.8769, lr_0 = 2.1544e-04
Validation r2 = 0.959274
Epoch 18
Validation r2 = 0.958076
Epoch 19
Loss = 1.0284e-02, PNorm = 34.2195, GNorm = 0.3891, lr_0 = 1.8277e-04
Validation r2 = 0.954315
Epoch 20
Loss = 1.0978e-02, PNorm = 34.2217, GNorm = 1.1434, lr_0 = 1.5719e-04
Validation r2 = 0.967367
Epoch 21
Validation r2 = 0.965271
Epoch 22
Loss = 8.2175e-03, PNorm = 34.2247, GNorm = 0.6729, lr_0 = 1.3519e-04
Validation r2 = 0.968669
Epoch 23
Validation r2 = 0.964142
Epoch 24
Loss = 7.5633e-03, PNorm = 34.2266, GNorm = 0.5904, lr_0 = 1.1469e-04
Validation r2 = 0.969735
Epoch 25
Loss = 6.1232e-03, PNorm = 34.2282, GNorm = 0.9485, lr_0 = 1.0000e-04
Validation r2 = 0.970664
Epoch 26
Validation r2 = 0.971410
Epoch 27
Loss = 8.1696e-03, PNorm = 34.2300, GNorm = 0.9091, lr_0 = 1.0000e-04
Validation r2 = 0.971738
Epoch 28
Loss = 7.1301e-03, PNorm = 34.2316, GNorm = 0.6021, lr_0 = 1.0000e-04
Loss = 4.2558e-03, PNorm = 34.2318, GNorm = 0.4856, lr_0 = 1.0000e-04
Validation r2 = 0.967523
Epoch 29
Validation r2 = 0.973559
Model 0 best validation r2 = 0.973559 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.990860
Ensemble test r2 = 0.990860
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.585503
Epoch 1
Loss = 3.4837e-01, PNorm = 34.0364, GNorm = 5.0971, lr_0 = 1.0000e-03
Validation r2 = 0.754580
Epoch 2
Validation r2 = 0.750238
Epoch 3
Loss = 1.2773e-01, PNorm = 34.0860, GNorm = 1.2680, lr_0 = 8.4834e-04
Validation r2 = 0.855362
Epoch 4
Loss = 1.1463e-01, PNorm = 34.1150, GNorm = 0.5298, lr_0 = 7.2962e-04
Validation r2 = 0.888457
Epoch 5
Validation r2 = 0.921928
Epoch 6
Loss = 5.5556e-02, PNorm = 34.1381, GNorm = 2.2795, lr_0 = 6.2751e-04
Validation r2 = 0.943562
Epoch 7
Validation r2 = 0.956880
Epoch 8
Loss = 3.5166e-02, PNorm = 34.1580, GNorm = 0.6930, lr_0 = 5.3234e-04
Validation r2 = 0.963656
Epoch 9
Loss = 2.3238e-02, PNorm = 34.1700, GNorm = 0.6087, lr_0 = 4.6416e-04
Validation r2 = 0.938180
Epoch 10
Validation r2 = 0.963066
Epoch 11
Loss = 2.2779e-02, PNorm = 34.1804, GNorm = 0.2799, lr_0 = 3.9377e-04
Validation r2 = 0.970668
Epoch 12
Loss = 1.8369e-02, PNorm = 34.1857, GNorm = 1.6214, lr_0 = 3.3866e-04
Validation r2 = 0.971362
Epoch 13
Validation r2 = 0.974520
Epoch 14
Loss = 1.1030e-02, PNorm = 34.1905, GNorm = 0.3454, lr_0 = 2.9126e-04
Validation r2 = 0.977188
Epoch 15
Validation r2 = 0.979477
Epoch 16
Loss = 8.4135e-03, PNorm = 34.1948, GNorm = 0.2910, lr_0 = 2.4709e-04
Validation r2 = 0.979348
Epoch 17
Loss = 1.3003e-02, PNorm = 34.1977, GNorm = 0.6543, lr_0 = 2.1544e-04
Validation r2 = 0.981607
Epoch 18
Validation r2 = 0.980636
Epoch 19
Loss = 1.2248e-02, PNorm = 34.2008, GNorm = 0.3970, lr_0 = 1.8277e-04
Validation r2 = 0.981078
Epoch 20
Loss = 1.1143e-02, PNorm = 34.2033, GNorm = 0.4212, lr_0 = 1.5719e-04
Validation r2 = 0.981583
Epoch 21
Validation r2 = 0.985090
Epoch 22
Loss = 1.3231e-02, PNorm = 34.2053, GNorm = 2.7967, lr_0 = 1.3519e-04
Validation r2 = 0.982684
Epoch 23
Validation r2 = 0.985686
Epoch 24
Loss = 8.0607e-03, PNorm = 34.2074, GNorm = 0.5000, lr_0 = 1.1469e-04
Validation r2 = 0.985225
Epoch 25
Loss = 9.6334e-03, PNorm = 34.2092, GNorm = 1.0194, lr_0 = 1.0000e-04
Validation r2 = 0.987500
Epoch 26
Validation r2 = 0.988239
Epoch 27
Loss = 1.0670e-02, PNorm = 34.2110, GNorm = 0.4056, lr_0 = 1.0000e-04
Validation r2 = 0.986567
Epoch 28
Loss = 6.9967e-03, PNorm = 34.2126, GNorm = 0.2998, lr_0 = 1.0000e-04
Loss = 3.2266e-02, PNorm = 34.2128, GNorm = 3.1074, lr_0 = 1.0000e-04
Validation r2 = 0.989035
Epoch 29
Validation r2 = 0.986867
Model 0 best validation r2 = 0.989035 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.984355
Ensemble test r2 = 0.984355
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.411659
Epoch 1
Loss = 3.3838e-01, PNorm = 34.0351, GNorm = 2.8112, lr_0 = 1.0000e-03
Validation r2 = 0.542088
Epoch 2
Validation r2 = 0.738290
Epoch 3
Loss = 1.7059e-01, PNorm = 34.0821, GNorm = 1.7675, lr_0 = 8.4834e-04
Validation r2 = 0.809503
Epoch 4
Loss = 1.2658e-01, PNorm = 34.1101, GNorm = 2.6227, lr_0 = 7.2962e-04
Validation r2 = 0.848805
Epoch 5
Validation r2 = 0.892355
Epoch 6
Loss = 8.1685e-02, PNorm = 34.1361, GNorm = 3.2431, lr_0 = 6.2751e-04
Validation r2 = 0.880236
Epoch 7
Validation r2 = 0.902093
Epoch 8
Loss = 1.0690e-01, PNorm = 34.1570, GNorm = 3.8240, lr_0 = 5.3234e-04
Validation r2 = 0.939397
Epoch 9
Loss = 6.0966e-02, PNorm = 34.1725, GNorm = 1.4321, lr_0 = 4.6416e-04
Validation r2 = 0.956214
Epoch 10
Validation r2 = 0.952021
Epoch 11
Loss = 2.9187e-02, PNorm = 34.1874, GNorm = 0.3991, lr_0 = 3.9377e-04
Validation r2 = 0.963610
Epoch 12
Loss = 2.9480e-02, PNorm = 34.1979, GNorm = 2.2498, lr_0 = 3.3866e-04
Validation r2 = 0.970871
Epoch 13
Validation r2 = 0.967018
Epoch 14
Loss = 2.5709e-02, PNorm = 34.2057, GNorm = 1.5081, lr_0 = 2.9126e-04
Validation r2 = 0.964928
Epoch 15
Validation r2 = 0.974369
Epoch 16
Loss = 1.7373e-02, PNorm = 34.2115, GNorm = 0.8425, lr_0 = 2.4709e-04
Validation r2 = 0.975315
Epoch 17
Loss = 1.3023e-02, PNorm = 34.2165, GNorm = 0.6091, lr_0 = 2.1544e-04
Validation r2 = 0.979578
Epoch 18
Validation r2 = 0.979877
Epoch 19
Loss = 9.7649e-03, PNorm = 34.2216, GNorm = 0.2607, lr_0 = 1.8277e-04
Validation r2 = 0.981593
Epoch 20
Loss = 1.2832e-02, PNorm = 34.2253, GNorm = 0.5531, lr_0 = 1.5719e-04
Validation r2 = 0.982464
Epoch 21
Validation r2 = 0.981878
Epoch 22
Loss = 9.2218e-03, PNorm = 34.2281, GNorm = 0.2593, lr_0 = 1.3519e-04
Validation r2 = 0.983566
Epoch 23
Validation r2 = 0.984524
Epoch 24
Loss = 8.9120e-03, PNorm = 34.2309, GNorm = 0.8562, lr_0 = 1.1469e-04
Validation r2 = 0.984756
Epoch 25
Loss = 9.2105e-03, PNorm = 34.2331, GNorm = 1.2244, lr_0 = 1.0000e-04
Validation r2 = 0.984760
Epoch 26
Validation r2 = 0.983525
Epoch 27
Loss = 9.2394e-03, PNorm = 34.2352, GNorm = 0.3687, lr_0 = 1.0000e-04
Validation r2 = 0.985589
Epoch 28
Loss = 8.7679e-03, PNorm = 34.2370, GNorm = 0.3561, lr_0 = 1.0000e-04
Loss = 9.9661e-03, PNorm = 34.2372, GNorm = 1.2603, lr_0 = 1.0000e-04
Validation r2 = 0.985246
Epoch 29
Validation r2 = 0.986568
Model 0 best validation r2 = 0.986568 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.991923
Ensemble test r2 = 0.991923
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.552473
Epoch 1
Loss = 4.5229e-01, PNorm = 34.0341, GNorm = 4.3608, lr_0 = 1.0000e-03
Validation r2 = 0.761664
Epoch 2
Validation r2 = 0.850724
Epoch 3
Loss = 1.5814e-01, PNorm = 34.0762, GNorm = 1.8448, lr_0 = 8.4834e-04
Validation r2 = 0.871234
Epoch 4
Loss = 1.3839e-01, PNorm = 34.1029, GNorm = 3.5197, lr_0 = 7.2962e-04
Validation r2 = 0.879698
Epoch 5
Validation r2 = 0.917230
Epoch 6
Loss = 9.1653e-02, PNorm = 34.1285, GNorm = 0.4753, lr_0 = 6.2751e-04
Validation r2 = 0.930068
Epoch 7
Validation r2 = 0.947198
Epoch 8
Loss = 5.7696e-02, PNorm = 34.1536, GNorm = 1.5387, lr_0 = 5.3234e-04
Validation r2 = 0.960270
Epoch 9
Loss = 3.0545e-02, PNorm = 34.1705, GNorm = 0.7204, lr_0 = 4.6416e-04
Validation r2 = 0.962321
Epoch 10
Validation r2 = 0.962609
Epoch 11
Loss = 3.2896e-02, PNorm = 34.1825, GNorm = 4.1073, lr_0 = 3.9377e-04
Validation r2 = 0.946394
Epoch 12
Loss = 3.1235e-02, PNorm = 34.1904, GNorm = 1.3849, lr_0 = 3.3866e-04
Validation r2 = 0.966874
Epoch 13
Validation r2 = 0.974408
Epoch 14
Loss = 2.3390e-02, PNorm = 34.1965, GNorm = 1.6068, lr_0 = 2.9126e-04
Validation r2 = 0.977880
Epoch 15
Validation r2 = 0.975945
Epoch 16
Loss = 1.6631e-02, PNorm = 34.2016, GNorm = 1.3249, lr_0 = 2.4709e-04
Validation r2 = 0.976804
Epoch 17
Loss = 1.4805e-02, PNorm = 34.2049, GNorm = 0.9556, lr_0 = 2.1544e-04
Validation r2 = 0.979906
Epoch 18
Validation r2 = 0.979877
Epoch 19
Loss = 1.2108e-02, PNorm = 34.2084, GNorm = 0.5851, lr_0 = 1.8277e-04
Validation r2 = 0.979933
Epoch 20
Loss = 1.0636e-02, PNorm = 34.2113, GNorm = 0.4807, lr_0 = 1.5719e-04
Validation r2 = 0.982975
Epoch 21
Validation r2 = 0.982662
Epoch 22
Loss = 9.1194e-03, PNorm = 34.2135, GNorm = 0.4178, lr_0 = 1.3519e-04
Validation r2 = 0.983612
Epoch 23
Validation r2 = 0.982987
Epoch 24
Loss = 1.3881e-02, PNorm = 34.2158, GNorm = 0.1652, lr_0 = 1.1469e-04
Validation r2 = 0.982242
Epoch 25
Loss = 8.9639e-03, PNorm = 34.2171, GNorm = 0.1861, lr_0 = 1.0000e-04
Validation r2 = 0.983341
Epoch 26
Validation r2 = 0.982209
Epoch 27
Loss = 1.0007e-02, PNorm = 34.2187, GNorm = 1.3526, lr_0 = 1.0000e-04
Validation r2 = 0.982421
Epoch 28
Loss = 8.4119e-03, PNorm = 34.2207, GNorm = 0.6498, lr_0 = 1.0000e-04
Loss = 5.4216e-03, PNorm = 34.2209, GNorm = 1.3206, lr_0 = 1.0000e-04
Validation r2 = 0.982972
Epoch 29
Validation r2 = 0.983724
Model 0 best validation r2 = 0.983724 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.981840
Ensemble test r2 = 0.981840
5-fold cross validation
	Seed 0 ==> test r2 = 0.936652
	Seed 1 ==> test r2 = 0.990860
	Seed 2 ==> test r2 = 0.984355
	Seed 3 ==> test r2 = 0.991923
	Seed 4 ==> test r2 = 0.981840
Overall test r2 = 0.977126 +/- 0.020592
Elapsed time = 0:04:24
Command line
python C:\Users\wanne\AppData\Roaming\Python\Python310\site-packages\ipykernel_launcher.py --f=c:\Users\wanne\AppData\Roaming\jupyter\runtime\kernel-v2-279162nLItqwfrYhX.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '../Trimers_Eat.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'r2',
 'metrics': ['r2'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'Checkpoints_Eat',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['Eat'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.543962
Epoch 1
Loss = 4.7373e-01, PNorm = 34.0357, GNorm = 6.2279, lr_0 = 1.0000e-03
Validation r2 = 0.797164
Epoch 2
Validation r2 = 0.770890
Epoch 3
Loss = 1.9245e-01, PNorm = 34.0808, GNorm = 1.2893, lr_0 = 8.4834e-04
Validation r2 = 0.846408
Epoch 4
Loss = 1.3923e-01, PNorm = 34.1082, GNorm = 1.5660, lr_0 = 7.2962e-04
Validation r2 = 0.864467
Epoch 5
Validation r2 = 0.913658
Epoch 6
Loss = 7.2040e-02, PNorm = 34.1327, GNorm = 2.1795, lr_0 = 6.2751e-04
Validation r2 = 0.923094
Epoch 7
Validation r2 = 0.932987
Epoch 8
Loss = 1.6376e-02, PNorm = 34.1559, GNorm = 0.7651, lr_0 = 5.3234e-04
Validation r2 = 0.945132
Epoch 9
Loss = 4.1296e-02, PNorm = 34.1714, GNorm = 0.5313, lr_0 = 4.6416e-04
Validation r2 = 0.947928
Epoch 10
Validation r2 = 0.957426
Epoch 11
Loss = 3.0459e-02, PNorm = 34.1844, GNorm = 2.5822, lr_0 = 3.9377e-04
Validation r2 = 0.953759
Epoch 12
Loss = 2.8514e-02, PNorm = 34.1932, GNorm = 2.5117, lr_0 = 3.3866e-04
Validation r2 = 0.968597
Epoch 13
Validation r2 = 0.969350
Epoch 14
Loss = 1.6685e-02, PNorm = 34.2010, GNorm = 0.3151, lr_0 = 2.9126e-04
Validation r2 = 0.971213
Epoch 15
Validation r2 = 0.976420
Epoch 16
Loss = 1.5162e-02, PNorm = 34.2073, GNorm = 0.4125, lr_0 = 2.4709e-04
Validation r2 = 0.978142
Epoch 17
Loss = 7.5618e-03, PNorm = 34.2110, GNorm = 0.4063, lr_0 = 2.1544e-04
Validation r2 = 0.979511
Epoch 18
Validation r2 = 0.980509
Epoch 19
Loss = 1.3759e-02, PNorm = 34.2145, GNorm = 1.3159, lr_0 = 1.8277e-04
Validation r2 = 0.980430
Epoch 20
Loss = 1.2404e-02, PNorm = 34.2176, GNorm = 1.0216, lr_0 = 1.5719e-04
Validation r2 = 0.979721
Epoch 21
Validation r2 = 0.979420
Epoch 22
Loss = 1.1737e-02, PNorm = 34.2202, GNorm = 0.1261, lr_0 = 1.3519e-04
Validation r2 = 0.983391
Epoch 23
Validation r2 = 0.980563
Epoch 24
Loss = 7.6808e-03, PNorm = 34.2227, GNorm = 0.6664, lr_0 = 1.1469e-04
Validation r2 = 0.983945
Epoch 25
Loss = 1.1834e-02, PNorm = 34.2245, GNorm = 1.5038, lr_0 = 1.0000e-04
Validation r2 = 0.984342
Epoch 26
Validation r2 = 0.981827
Epoch 27
Loss = 9.2221e-03, PNorm = 34.2267, GNorm = 0.1921, lr_0 = 1.0000e-04
Validation r2 = 0.984626
Epoch 28
Loss = 8.5818e-03, PNorm = 34.2287, GNorm = 0.6680, lr_0 = 1.0000e-04
Loss = 1.0812e-02, PNorm = 34.2289, GNorm = 0.2560, lr_0 = 1.0000e-04
Validation r2 = 0.985406
Epoch 29
Validation r2 = 0.984700
Model 0 best validation r2 = 0.985406 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.936717
Ensemble test r2 = 0.936717
Fold 1
Splitting data with seed 1
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.678855
Epoch 1
Loss = 4.0609e-01, PNorm = 34.0365, GNorm = 1.9368, lr_0 = 1.0000e-03
Validation r2 = 0.765773
Epoch 2
Validation r2 = 0.826563
Epoch 3
Loss = 1.3259e-01, PNorm = 34.0875, GNorm = 1.2401, lr_0 = 8.4834e-04
Validation r2 = 0.609971
Epoch 4
Loss = 1.4120e-01, PNorm = 34.1200, GNorm = 2.2627, lr_0 = 7.2962e-04
Validation r2 = 0.774270
Epoch 5
Validation r2 = 0.850510
Epoch 6
Loss = 8.0233e-02, PNorm = 34.1450, GNorm = 0.7506, lr_0 = 6.2751e-04
Validation r2 = 0.857110
Epoch 7
Validation r2 = 0.921203
Epoch 8
Loss = 4.7481e-02, PNorm = 34.1689, GNorm = 1.7296, lr_0 = 5.3234e-04
Validation r2 = 0.932248
Epoch 9
Loss = 2.9667e-02, PNorm = 34.1850, GNorm = 1.6332, lr_0 = 4.6416e-04
Validation r2 = 0.937949
Epoch 10
Validation r2 = 0.941657
Epoch 11
Loss = 2.7763e-02, PNorm = 34.1946, GNorm = 0.7262, lr_0 = 3.9377e-04
Validation r2 = 0.948831
Epoch 12
Loss = 1.6949e-02, PNorm = 34.2013, GNorm = 0.4391, lr_0 = 3.3866e-04
Validation r2 = 0.948890
Epoch 13
Validation r2 = 0.946409
Epoch 14
Loss = 1.4171e-02, PNorm = 34.2071, GNorm = 0.2471, lr_0 = 2.9126e-04
Validation r2 = 0.956297
Epoch 15
Validation r2 = 0.959425
Epoch 16
Loss = 1.6893e-02, PNorm = 34.2123, GNorm = 0.5474, lr_0 = 2.4709e-04
Validation r2 = 0.962591
Epoch 17
Loss = 1.0863e-02, PNorm = 34.2161, GNorm = 0.8769, lr_0 = 2.1544e-04
Validation r2 = 0.959274
Epoch 18
Validation r2 = 0.958076
Epoch 19
Loss = 1.0284e-02, PNorm = 34.2195, GNorm = 0.3891, lr_0 = 1.8277e-04
Validation r2 = 0.954315
Epoch 20
Loss = 1.0978e-02, PNorm = 34.2217, GNorm = 1.1434, lr_0 = 1.5719e-04
Validation r2 = 0.967367
Epoch 21
Validation r2 = 0.965271
Epoch 22
Loss = 8.2175e-03, PNorm = 34.2247, GNorm = 0.6729, lr_0 = 1.3519e-04
Validation r2 = 0.968669
Epoch 23
Validation r2 = 0.964142
Epoch 24
Loss = 7.5633e-03, PNorm = 34.2266, GNorm = 0.5904, lr_0 = 1.1469e-04
Validation r2 = 0.969735
Epoch 25
Loss = 6.1232e-03, PNorm = 34.2282, GNorm = 0.9485, lr_0 = 1.0000e-04
Validation r2 = 0.970664
Epoch 26
Validation r2 = 0.971410
Epoch 27
Loss = 8.1696e-03, PNorm = 34.2300, GNorm = 0.9091, lr_0 = 1.0000e-04
Validation r2 = 0.971738
Epoch 28
Loss = 7.1301e-03, PNorm = 34.2316, GNorm = 0.6021, lr_0 = 1.0000e-04
Loss = 4.2558e-03, PNorm = 34.2318, GNorm = 0.4856, lr_0 = 1.0000e-04
Validation r2 = 0.967523
Epoch 29
Validation r2 = 0.973559
Model 0 best validation r2 = 0.973559 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.990860
Ensemble test r2 = 0.990860
Fold 2
Splitting data with seed 2
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.585503
Epoch 1
Loss = 3.4837e-01, PNorm = 34.0364, GNorm = 5.0971, lr_0 = 1.0000e-03
Validation r2 = 0.754580
Epoch 2
Validation r2 = 0.750238
Epoch 3
Loss = 1.2773e-01, PNorm = 34.0860, GNorm = 1.2680, lr_0 = 8.4834e-04
Validation r2 = 0.855362
Epoch 4
Loss = 1.1463e-01, PNorm = 34.1150, GNorm = 0.5298, lr_0 = 7.2962e-04
Validation r2 = 0.888457
Epoch 5
Validation r2 = 0.921928
Epoch 6
Loss = 5.5556e-02, PNorm = 34.1381, GNorm = 2.2795, lr_0 = 6.2751e-04
Validation r2 = 0.943562
Epoch 7
Validation r2 = 0.956880
Epoch 8
Loss = 3.5166e-02, PNorm = 34.1580, GNorm = 0.6930, lr_0 = 5.3234e-04
Validation r2 = 0.963656
Epoch 9
Loss = 2.3238e-02, PNorm = 34.1700, GNorm = 0.6087, lr_0 = 4.6416e-04
Validation r2 = 0.938180
Epoch 10
Validation r2 = 0.963066
Epoch 11
Loss = 2.2779e-02, PNorm = 34.1804, GNorm = 0.2799, lr_0 = 3.9377e-04
Validation r2 = 0.970668
Epoch 12
Loss = 1.8369e-02, PNorm = 34.1857, GNorm = 1.6214, lr_0 = 3.3866e-04
Validation r2 = 0.971362
Epoch 13
Validation r2 = 0.974520
Epoch 14
Loss = 1.1030e-02, PNorm = 34.1905, GNorm = 0.3454, lr_0 = 2.9126e-04
Validation r2 = 0.977188
Epoch 15
Validation r2 = 0.979477
Epoch 16
Loss = 8.4135e-03, PNorm = 34.1948, GNorm = 0.2910, lr_0 = 2.4709e-04
Validation r2 = 0.979348
Epoch 17
Loss = 1.3003e-02, PNorm = 34.1977, GNorm = 0.6543, lr_0 = 2.1544e-04
Validation r2 = 0.981607
Epoch 18
Validation r2 = 0.980636
Epoch 19
Loss = 1.2248e-02, PNorm = 34.2008, GNorm = 0.3970, lr_0 = 1.8277e-04
Validation r2 = 0.981078
Epoch 20
Loss = 1.1143e-02, PNorm = 34.2033, GNorm = 0.4212, lr_0 = 1.5719e-04
Validation r2 = 0.981583
Epoch 21
Validation r2 = 0.985090
Epoch 22
Loss = 1.3231e-02, PNorm = 34.2053, GNorm = 2.7967, lr_0 = 1.3519e-04
Validation r2 = 0.982684
Epoch 23
Validation r2 = 0.985686
Epoch 24
Loss = 8.0607e-03, PNorm = 34.2074, GNorm = 0.5000, lr_0 = 1.1469e-04
Validation r2 = 0.985225
Epoch 25
Loss = 9.6334e-03, PNorm = 34.2092, GNorm = 1.0194, lr_0 = 1.0000e-04
Validation r2 = 0.987500
Epoch 26
Validation r2 = 0.988239
Epoch 27
Loss = 1.0670e-02, PNorm = 34.2110, GNorm = 0.4056, lr_0 = 1.0000e-04
Validation r2 = 0.986567
Epoch 28
Loss = 6.9967e-03, PNorm = 34.2126, GNorm = 0.2998, lr_0 = 1.0000e-04
Loss = 3.2266e-02, PNorm = 34.2128, GNorm = 3.1074, lr_0 = 1.0000e-04
Validation r2 = 0.989035
Epoch 29
Validation r2 = 0.986867
Model 0 best validation r2 = 0.989035 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.984355
Ensemble test r2 = 0.984355
Fold 3
Splitting data with seed 3
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.411659
Epoch 1
Loss = 3.3838e-01, PNorm = 34.0351, GNorm = 2.8112, lr_0 = 1.0000e-03
Validation r2 = 0.542088
Epoch 2
Validation r2 = 0.738290
Epoch 3
Loss = 1.7059e-01, PNorm = 34.0821, GNorm = 1.7675, lr_0 = 8.4834e-04
Validation r2 = 0.809503
Epoch 4
Loss = 1.2658e-01, PNorm = 34.1101, GNorm = 2.6227, lr_0 = 7.2962e-04
Validation r2 = 0.848805
Epoch 5
Validation r2 = 0.892355
Epoch 6
Loss = 8.1685e-02, PNorm = 34.1361, GNorm = 3.2431, lr_0 = 6.2751e-04
Validation r2 = 0.880236
Epoch 7
Validation r2 = 0.902093
Epoch 8
Loss = 1.0690e-01, PNorm = 34.1570, GNorm = 3.8240, lr_0 = 5.3234e-04
Validation r2 = 0.939397
Epoch 9
Loss = 6.0966e-02, PNorm = 34.1725, GNorm = 1.4321, lr_0 = 4.6416e-04
Validation r2 = 0.956214
Epoch 10
Validation r2 = 0.952021
Epoch 11
Loss = 2.9187e-02, PNorm = 34.1874, GNorm = 0.3991, lr_0 = 3.9377e-04
Validation r2 = 0.963610
Epoch 12
Loss = 2.9480e-02, PNorm = 34.1979, GNorm = 2.2498, lr_0 = 3.3866e-04
Validation r2 = 0.970871
Epoch 13
Validation r2 = 0.967018
Epoch 14
Loss = 2.5709e-02, PNorm = 34.2057, GNorm = 1.5081, lr_0 = 2.9126e-04
Validation r2 = 0.964928
Epoch 15
Validation r2 = 0.974369
Epoch 16
Loss = 1.7373e-02, PNorm = 34.2115, GNorm = 0.8425, lr_0 = 2.4709e-04
Validation r2 = 0.975315
Epoch 17
Loss = 1.3023e-02, PNorm = 34.2165, GNorm = 0.6091, lr_0 = 2.1544e-04
Validation r2 = 0.979578
Epoch 18
Validation r2 = 0.979877
Epoch 19
Loss = 9.7649e-03, PNorm = 34.2216, GNorm = 0.2607, lr_0 = 1.8277e-04
Validation r2 = 0.981593
Epoch 20
Loss = 1.2832e-02, PNorm = 34.2253, GNorm = 0.5531, lr_0 = 1.5719e-04
Validation r2 = 0.982464
Epoch 21
Validation r2 = 0.981878
Epoch 22
Loss = 9.2218e-03, PNorm = 34.2281, GNorm = 0.2593, lr_0 = 1.3519e-04
Validation r2 = 0.983566
Epoch 23
Validation r2 = 0.984524
Epoch 24
Loss = 8.9120e-03, PNorm = 34.2309, GNorm = 0.8562, lr_0 = 1.1469e-04
Validation r2 = 0.984756
Epoch 25
Loss = 9.2105e-03, PNorm = 34.2331, GNorm = 1.2244, lr_0 = 1.0000e-04
Validation r2 = 0.984760
Epoch 26
Validation r2 = 0.983525
Epoch 27
Loss = 9.2394e-03, PNorm = 34.2352, GNorm = 0.3687, lr_0 = 1.0000e-04
Validation r2 = 0.985589
Epoch 28
Loss = 8.7679e-03, PNorm = 34.2370, GNorm = 0.3561, lr_0 = 1.0000e-04
Loss = 9.9661e-03, PNorm = 34.2372, GNorm = 1.2603, lr_0 = 1.0000e-04
Validation r2 = 0.985246
Epoch 29
Validation r2 = 0.986568
Model 0 best validation r2 = 0.986568 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.991923
Ensemble test r2 = 0.991923
Fold 4
Splitting data with seed 4
Total size = 390 | train size = 312 | val size = 39 | test size = 39
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Validation r2 = 0.552473
Epoch 1
Loss = 4.5229e-01, PNorm = 34.0341, GNorm = 4.3608, lr_0 = 1.0000e-03
Validation r2 = 0.761664
Epoch 2
Validation r2 = 0.850724
Epoch 3
Loss = 1.5814e-01, PNorm = 34.0762, GNorm = 1.8448, lr_0 = 8.4834e-04
Validation r2 = 0.871234
Epoch 4
Loss = 1.3839e-01, PNorm = 34.1029, GNorm = 3.5197, lr_0 = 7.2962e-04
Validation r2 = 0.879698
Epoch 5
Validation r2 = 0.917230
Epoch 6
Loss = 9.1653e-02, PNorm = 34.1285, GNorm = 0.4753, lr_0 = 6.2751e-04
Validation r2 = 0.930068
Epoch 7
Validation r2 = 0.947198
Epoch 8
Loss = 5.7696e-02, PNorm = 34.1536, GNorm = 1.5387, lr_0 = 5.3234e-04
Validation r2 = 0.960270
Epoch 9
Loss = 3.0545e-02, PNorm = 34.1705, GNorm = 0.7204, lr_0 = 4.6416e-04
Validation r2 = 0.962321
Epoch 10
Validation r2 = 0.962609
Epoch 11
Loss = 3.2896e-02, PNorm = 34.1825, GNorm = 4.1073, lr_0 = 3.9377e-04
Validation r2 = 0.946394
Epoch 12
Loss = 3.1235e-02, PNorm = 34.1904, GNorm = 1.3849, lr_0 = 3.3866e-04
Validation r2 = 0.966874
Epoch 13
Validation r2 = 0.974408
Epoch 14
Loss = 2.3390e-02, PNorm = 34.1965, GNorm = 1.6068, lr_0 = 2.9126e-04
Validation r2 = 0.977880
Epoch 15
Validation r2 = 0.975945
Epoch 16
Loss = 1.6631e-02, PNorm = 34.2016, GNorm = 1.3249, lr_0 = 2.4709e-04
Validation r2 = 0.976804
Epoch 17
Loss = 1.4805e-02, PNorm = 34.2049, GNorm = 0.9556, lr_0 = 2.1544e-04
Validation r2 = 0.979906
Epoch 18
Validation r2 = 0.979877
Epoch 19
Loss = 1.2108e-02, PNorm = 34.2084, GNorm = 0.5851, lr_0 = 1.8277e-04
Validation r2 = 0.979933
Epoch 20
Loss = 1.0636e-02, PNorm = 34.2113, GNorm = 0.4807, lr_0 = 1.5719e-04
Validation r2 = 0.982975
Epoch 21
Validation r2 = 0.982662
Epoch 22
Loss = 9.1194e-03, PNorm = 34.2135, GNorm = 0.4178, lr_0 = 1.3519e-04
Validation r2 = 0.983612
Epoch 23
Validation r2 = 0.982987
Epoch 24
Loss = 1.3881e-02, PNorm = 34.2158, GNorm = 0.1652, lr_0 = 1.1469e-04
Validation r2 = 0.982242
Epoch 25
Loss = 8.9639e-03, PNorm = 34.2171, GNorm = 0.1861, lr_0 = 1.0000e-04
Validation r2 = 0.983341
Epoch 26
Validation r2 = 0.982209
Epoch 27
Loss = 1.0007e-02, PNorm = 34.2187, GNorm = 1.3526, lr_0 = 1.0000e-04
Validation r2 = 0.982421
Epoch 28
Loss = 8.4119e-03, PNorm = 34.2207, GNorm = 0.6498, lr_0 = 1.0000e-04
Loss = 5.4216e-03, PNorm = 34.2209, GNorm = 1.3206, lr_0 = 1.0000e-04
Validation r2 = 0.982972
Epoch 29
Validation r2 = 0.983724
Model 0 best validation r2 = 0.983724 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test r2 = 0.981840
Ensemble test r2 = 0.981840
5-fold cross validation
	Seed 0 ==> test r2 = 0.936717
	Seed 1 ==> test r2 = 0.990860
	Seed 2 ==> test r2 = 0.984355
	Seed 3 ==> test r2 = 0.991923
	Seed 4 ==> test r2 = 0.981840
Overall test r2 = 0.977139 +/- 0.020567
Elapsed time = 0:04:47
