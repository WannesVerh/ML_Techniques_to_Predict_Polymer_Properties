{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wanne\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Error: Unable to import pysam. Please make sure it is installed.\n",
      "Error: Unable to import pysam. Please make sure it is installed.\n",
      "Error: Unable to import pysam. Please make sure it is installed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script that trains sklearn models on HOPV dataset.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stderr():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stderr = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "with suppress_stderr():            \n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    import deepchem as dc\n",
    "    from deepchem.molnet import load_hopv\n",
    "    from deepchem.models import GraphConvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "Train scores\n",
      "{'mean-pearson_r2_score': 0.054204356778130125, 'mean-mean_absolute_error': 2.9276148361601484}\n",
      "Validation scores\n",
      "{'mean-pearson_r2_score': 0.0893439194223038, 'mean-mean_absolute_error': 3.311179397972712}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script that trains graph-conv models on HOPV dataset.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)\n",
    "import deepchem as dc\n",
    "from deepchem.molnet import load_hopv\n",
    "\n",
    "# Load HOPV dataset\n",
    "hopv_tasks, hopv_datasets, transformers = load_hopv(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = hopv_datasets\n",
    "\n",
    "# Fit models\n",
    "metric = [\n",
    "    dc.metrics.Metric(dc.metrics.pearson_r2_score, np.mean, mode=\"regression\"),\n",
    "    dc.metrics.Metric(\n",
    "        dc.metrics.mean_absolute_error, np.mean, mode=\"regression\")\n",
    "]\n",
    "\n",
    "# Number of features on conv-mols\n",
    "n_feat = 75\n",
    "# Batch size of models\n",
    "batch_size = 50\n",
    "model = GraphConvModel(\n",
    "    len(hopv_tasks), batch_size=batch_size, mode='regression')\n",
    "\n",
    "# Fit trained model\n",
    "model.fit(train_dataset, nb_epoch=25)\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_dataset, metric, transformers)\n",
    "valid_scores = model.evaluate(valid_dataset, metric, transformers)\n",
    "\n",
    "print(\"Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"Validation scores\")\n",
    "print(valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HOPV dataset\n",
    "hopv_tasks, hopv_datasets, transformers = load_hopv(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = hopv_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features on conv-mols\n",
    "n_feat = 75\n",
    "# Batch size of models\n",
    "batch_size = 50\n",
    "model = GraphConvModel(\n",
    "    len(hopv_tasks), batch_size=batch_size, mode='regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to fit model\n"
     ]
    }
   ],
   "source": [
    "# Fit trained model\n",
    "print(\"About to fit model\")\n",
    "model.fit(train_dataset, nb_epoch=25)\n",
    "predicted = model.predict(valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = [\n",
    "    dc.metrics.Metric(dc.metrics.pearson_r2_score, np.mean, mode=\"regression\"),\n",
    "    dc.metrics.Metric(\n",
    "        dc.metrics.mean_absolute_error, np.mean, mode=\"regression\")\n",
    "]\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_dataset, metric, transformers)\n",
    "valid_scores = model.evaluate(valid_dataset, metric, transformers)\n",
    "\n",
    "print(\"Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"Validation scores\")\n",
    "print(valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: {'pearson_r2_score': 0.40445718254258284}\n",
      "valid score: {'pearson_r2_score': 0.2238404376377698}\n",
      "pearson r2 valid score for: HOMO is 0.015196617078727126\n",
      "pearson r2 valid score for: LUMO is 0.03757244597222908\n",
      "pearson r2 valid score for: electrochemical_gap is 0.0022112574045139934\n",
      "pearson r2 valid score for: optical_gap is 0.0035849562834221064\n",
      "pearson r2 valid score for: PCE is 0.5906037603201933\n",
      "pearson r2 valid score for: V_OC is 0.2107968830893046\n",
      "pearson r2 valid score for: J_SC is 0.5045504078503797\n",
      "pearson r2 valid score for: fill_factor is 0.42620717310338896\n"
     ]
    }
   ],
   "source": [
    "#the avarage score is:\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score, mode=\"regression\")\n",
    "print(\"training score:\",model.evaluate(train_dataset, metric, transformers))\n",
    "print(\"valid score:\",model.evaluate(valid_dataset, metric, transformers))\n",
    "\n",
    "for i in range(0,8):\n",
    "    x = np.concatenate( valid_dataset.y[:,[i]], axis=0 )\n",
    "    y = np.concatenate( predicted[:,[i]], axis=0 )\n",
    "    print(\"pearson r2 valid score for:\",valid_dataset.tasks[i],\"is\",dc.metrics.pearson_r2_score(x,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
